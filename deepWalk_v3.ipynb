{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b307a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pickle as p\n",
    "from os import path\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "\n",
    "data_loc = 'C:/Users/alex_/Fac/M2/M2/S2/Discrete_Graphs/Projet/Data/BlogCatalog3/BlogCatalog-dataset/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba68a41f",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07063a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:  10312\n",
      "Number of edges:  333983\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    iid = {}\n",
    "    idx = 0\n",
    "    edgelist = []\n",
    "\n",
    "    # Read edges pairs\n",
    "    with open(data_loc+'edges.csv', 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            i, j = line.strip().split(',')  # csv\n",
    "            if i not in iid:\n",
    "                iid[i] = idx; idx += 1\n",
    "            if j not in iid:\n",
    "                iid[j] = idx; idx += 1\n",
    "            edgelist.append((iid[i], iid[j]))\n",
    "\n",
    "    # Create an nx undirected network\n",
    "    bc = nx.Graph(edgelist)\n",
    "\n",
    "    print(\"Number of nodes: \", len(bc))\n",
    "    print(\"Number of edges: \", bc.size())\n",
    "\n",
    "    # Read labels\n",
    "    labels = np.zeros((len(bc)), dtype=int)\n",
    "    # Read (node_id, label) file\n",
    "    with open(data_loc+'group-edges.csv', 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            node, group = line.strip().split(',') \n",
    "            labels[iid[node]] = int(group)-1  \n",
    "\n",
    "    bc_dataset = {'graph': bc, 'labels': labels}\n",
    "    return bc_dataset\n",
    "\n",
    "bc_dataset = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e5baaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "38\n",
      "[[   0   60]\n",
      " [   1  488]\n",
      " [   2  365]\n",
      " [   3  119]\n",
      " [   4  625]\n",
      " [   5  563]\n",
      " [   6  393]\n",
      " [   7 1076]\n",
      " [   8  247]\n",
      " [   9  300]\n",
      " [  10  325]\n",
      " [  11   25]\n",
      " [  12   35]\n",
      " [  13  239]\n",
      " [  14   53]\n",
      " [  15  295]\n",
      " [  16  351]\n",
      " [  17  236]\n",
      " [  18  715]\n",
      " [  19  247]\n",
      " [  20  228]\n",
      " [  21  233]\n",
      " [  22  279]\n",
      " [  23  846]\n",
      " [  24  170]\n",
      " [  25  242]\n",
      " [  26   88]\n",
      " [  27   85]\n",
      " [  28  155]\n",
      " [  29  360]\n",
      " [  30   62]\n",
      " [  31  371]\n",
      " [  32   91]\n",
      " [  33   62]\n",
      " [  34   58]\n",
      " [  35  137]\n",
      " [  36   53]\n",
      " [  37   27]\n",
      " [  38    8]]\n"
     ]
    }
   ],
   "source": [
    "print(np.min(bc_dataset['labels']))\n",
    "print(np.max(bc_dataset['labels']))\n",
    "unique, counts = np.unique(bc_dataset['labels'], return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82ae8b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   65,  924,  240, 1146],\n",
       "        [   0,  113,  422,  633, 4516],\n",
       "        [   0,   77,  361, 4874,  399]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def gen_biaised_random_walk_tensor(graph, start_node, walk_length, num_walks, p, q):\n",
    "    walk = torch.zeros((num_walks, walk_length), dtype=int)\n",
    "    walk[:, 0] = start_node\n",
    "    j = 0\n",
    "    while j < num_walks:\n",
    "        current_node = start_node\n",
    "        step = 1\n",
    "        while step < walk_length:\n",
    "            neighbors = list(graph.neighbors(current_node))\n",
    "            if step == 1:\n",
    "                current_node = random.choice(neighbors)\n",
    "            else:\n",
    "                prev_node = walk[j,step-1]\n",
    "                current_node = biased_choose_next_node(graph, current_node, prev_node, p, q)\n",
    "            walk[j, step] = current_node\n",
    "            step += 1\n",
    "        j+=1\n",
    "    return walk\n",
    "\n",
    "\n",
    "def biased_choose_next_node(graph, current_node, prev_node, p, q):\n",
    "    neighbors = list(graph.neighbors(current_node))\n",
    "    weights = []\n",
    "    for neighbor in neighbors:\n",
    "        if neighbor == prev_node:\n",
    "            weights.append(1/p)\n",
    "        elif graph.has_edge(prev_node, neighbor):\n",
    "            weights.append(1)\n",
    "        else:\n",
    "            weights.append(1/q)\n",
    "    return random.choices(neighbors, weights=weights)[0]\n",
    "\n",
    "def gen_biaised_random_walk_tensor(graph, start_node, walk_length, num_walks, p, q , neighbors_dict):\n",
    "    walks = torch.zeros((num_walks, walk_length), dtype=int)\n",
    "    walks[:, 0] = start_node\n",
    "\n",
    "    for walk_index in range(num_walks):\n",
    "        current_node = start_node\n",
    "        for step in range(walk_length):\n",
    "            walks[walk_index, step] = current_node\n",
    "            neighbors = neighbors_dict[current_node]\n",
    "            if step > 0:\n",
    "                prev_node = walks[walk_index, step - 1]\n",
    "            else:\n",
    "                prev_node = None\n",
    "            current_node = biased_choose_next_node(neighbors, prev_node, p, q, graph)\n",
    "    \n",
    "    return walks\n",
    "\n",
    "def biased_choose_next_node(neighbors, prev_node, p, q, graph):\n",
    "    weights = []\n",
    "    for neighbor in neighbors:\n",
    "        if neighbor == prev_node:\n",
    "            weights.append(1/p)\n",
    "        elif graph.has_edge(prev_node, neighbor):\n",
    "            weights.append(1)\n",
    "        else:\n",
    "            weights.append(1/q)\n",
    "    return random.choices(neighbors, weights=weights)[0]\n",
    "\n",
    "# Assert all edges exist\n",
    "graph = bc_dataset['graph']\n",
    "neighbors_dict = {node: list(graph.neighbors(node)) for node in graph.nodes}\n",
    "rws = gen_biaised_random_walk_tensor(bc_dataset['graph'], 0, 5, 3, 5, 5, neighbors_dict)\n",
    "rws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e89a581",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:80] data. DefaultCPUAllocator: not enough memory: you tried to allocate 4386202765312 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m             neighbors_probabilities[node, node2,node2] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mp\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m neighbors_probabilities\n\u001b[1;32m---> 26\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_neighbors_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m test\u001b[38;5;241m.\u001b[39munique(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[67], line 3\u001b[0m, in \u001b[0;36mcalculate_neighbors_probabilities\u001b[1;34m(graph, p, q)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_neighbors_probabilities\u001b[39m(graph, p, q):\n\u001b[0;32m      2\u001b[0m     num_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(graph\u001b[38;5;241m.\u001b[39mnodes)\n\u001b[1;32m----> 3\u001b[0m     neighbors_probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mnodes:\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m node2 \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mnodes:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:80] data. DefaultCPUAllocator: not enough memory: you tried to allocate 4386202765312 bytes."
     ]
    }
   ],
   "source": [
    "def calculate_neighbors_probabilities(graph, p, q):\n",
    "    num_nodes = len(graph.nodes)\n",
    "    neighbors_probabilities = torch.zeros((num_nodes, num_nodes,num_nodes), dtype=torch.float)\n",
    "\n",
    "    for node in graph.nodes:\n",
    "        for node2 in graph.nodes:\n",
    "            neighbors = list(graph.neighbors(node))\n",
    "            is_neighbor = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "            is_neighbor[neighbors] = True\n",
    "\n",
    "            # Probability for self-loop\n",
    "            self_loop_prob = 1 / q\n",
    "            neighbors_probabilities[node,node2, is_neighbor] = 1/q\n",
    "\n",
    "            # Probability for edge present\n",
    "            neighbors2 = list(graph.neighbors(node))\n",
    "            is_neighbor2 = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "            is_neighbor2[neighbors2] = True\n",
    "            neighbors_probabilities[node,node2, is_neighbor & is_neighbor2] = 1\n",
    "\n",
    "\n",
    "            neighbors_probabilities[node, node2,node2] = 1/p\n",
    "\n",
    "    return neighbors_probabilities\n",
    "\n",
    "test = calculate_neighbors_probabilities(graph, 5, 5)\n",
    "test.unique(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec1754be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         41131 function calls in 0.044 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       15    0.034    0.002    0.043    0.003 476093457.py:53(biased_choose_next_node)\n",
      "    10427    0.006    0.000    0.008    0.000 graph.py:1274(has_edge)\n",
      "    10070    0.002    0.000    0.002    0.000 _tensor.py:1002(__hash__)\n",
      "    10439    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}\n",
      "    10070    0.001    0.000    0.001    0.000 {built-in method builtins.id}\n",
      "        1    0.000    0.000    0.044    0.044 476093457.py:36(gen_biaised_random_walk_tensor)\n",
      "       15    0.000    0.000    0.000    0.000 random.py:480(choices)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.zeros}\n",
      "        1    0.000    0.000    0.044    0.044 {built-in method builtins.exec}\n",
      "       15    0.000    0.000    0.000    0.000 random.py:514(<listcomp>)\n",
      "       15    0.000    0.000    0.000    0.000 {built-in method _bisect.bisect_right}\n",
      "       30    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.044    0.044 <string>:1(<module>)\n",
      "       15    0.000    0.000    0.000    0.000 {method 'random' of '_random.Random' objects}\n",
      "       15    0.000    0.000    0.000    0.000 {built-in method math.isfinite}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}"
     ]
    }
   ],
   "source": [
    "%prun gen_biaised_random_walk_tensor(bc_dataset['graph'], 0, 5, 3, 5, 5, neighbors_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e24c28d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch_biaised_random_walk(graph, initial_nodes, length, num_walks, p, q, neighbors_dict):\n",
    "    n_nodes = initial_nodes.shape[0]\n",
    "    walk = torch.zeros((num_walks*n_nodes, length), dtype=int)\n",
    "    for i, n in enumerate(initial_nodes):\n",
    "        n = n.item()\n",
    "        walk[num_walks*i:num_walks*(i+1)] = gen_biaised_random_walk_tensor(graph, n, length, num_walks, p, q,neighbors_dict)\n",
    "    return walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "343314b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   51, 2736, 6419,   38],\n",
       "        [   0,   78, 3874,  748,  109],\n",
       "        [   0,   91, 1617,  742,  175],\n",
       "        [   1, 4534,  607, 4511, 4468],\n",
       "        [   1, 2952,  246, 2413, 4067],\n",
       "        [   1, 2763,  637, 2763, 1179]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw = gen_batch_biaised_random_walk(bc_dataset['graph'], torch.tensor([0, 1]), 5, 3, 5, 5, neighbors_dict)\n",
    "rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57636b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   51, 2736],\n",
       "        [   0,   78, 3874],\n",
       "        [   0,   91, 1617],\n",
       "        [   1, 4534,  607],\n",
       "        [   1, 2952,  246],\n",
       "        [   1, 2763,  637],\n",
       "        [  51, 2736, 6419],\n",
       "        [  78, 3874,  748],\n",
       "        [  91, 1617,  742],\n",
       "        [4534,  607, 4511],\n",
       "        [2952,  246, 2413],\n",
       "        [2763,  637, 2763],\n",
       "        [2736, 6419,   38],\n",
       "        [3874,  748,  109],\n",
       "        [1617,  742,  175],\n",
       "        [ 607, 4511, 4468],\n",
       "        [ 246, 2413, 4067],\n",
       "        [ 637, 2763, 1179]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_windows(random_walk, window_size):\n",
    "    num_walks, walk_length = random_walk.shape\n",
    "    # number of windows: e.g. length 5, window size 3 -> 3 windows ([0, 1, 2], [1, 2, 3], [2, 3, 4])\n",
    "    num_windows = walk_length + 1 - window_size\n",
    "    windows = torch.zeros((num_walks*num_windows, window_size), dtype=int)\n",
    "    for j in range(num_windows):\n",
    "        windows[num_walks*j:num_walks*(j+1)] = random_walk[:, j:j+window_size]\n",
    "    return windows\n",
    "\n",
    "windows = generate_windows(rw, 3)\n",
    "windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b455fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.3160e-01, -1.7453e+01],\n",
       "        [ 3.6259e+00, -6.2958e+00],\n",
       "        [ 2.3249e+01,  2.5632e+01],\n",
       "        [-7.8575e-01,  2.5061e+01],\n",
       "        [-1.4811e+01, -6.1414e-02],\n",
       "        [ 2.2851e+01,  2.4319e+01],\n",
       "        [ 7.5281e+00,  1.1706e+01],\n",
       "        [-4.9315e+00, -2.1798e+01],\n",
       "        [ 2.0038e+01,  2.3418e+01],\n",
       "        [-1.6915e+01, -1.2928e+01],\n",
       "        [-1.5913e+01, -1.0094e+01],\n",
       "        [ 1.5043e+01,  2.9947e+02],\n",
       "        [-7.4257e+00,  1.6662e+01],\n",
       "        [ 3.7985e+01,  7.3073e-01],\n",
       "        [-3.2438e+01,  1.4054e+01],\n",
       "        [ 3.8109e+00,  1.8080e+01],\n",
       "        [-3.7073e+01,  3.5246e+00],\n",
       "        [ 1.5043e+01, -5.1523e+00]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_windows_dotproduct(windows, embedding):\n",
    "    embedding_size = embedding.shape[1]\n",
    "    # get the embedding of the initial node repeated num_windows times\n",
    "    first_emb = embedding[windows[:, 0]]\n",
    "    first_emb = first_emb.view(windows.shape[0], 1, embedding_size)\n",
    "    # get the embedding of the remaining nodes in each window\n",
    "    others_emb = embedding[windows[:, 1:]]\n",
    "    others_emb = others_emb.view(windows.shape[0], -1, embedding_size)\n",
    "    # result has same shape as others\n",
    "    # Each element is the dot product between the corresponding node embedding\n",
    "    # and the embedding of the first node of that walk\n",
    "    # that is, result_{i, j} for random walk i and element j is v_{W_{i, 0}} dot v_{W_{i, j}}\n",
    "    result = (first_emb*others_emb).sum(dim=-1)\n",
    "    return result\n",
    "\n",
    "embedding = torch.randn((12000, 300))\n",
    "get_windows_dotproduct(windows, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69c57727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.7423)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(torch.sigmoid(get_windows_dotproduct(windows, embedding))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8b31f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,  489, 1871, 1107,   13],\n",
       "        [   0, 1473,  616, 1278, 1778],\n",
       "        [   0, 1766, 1265,  178, 1613]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_negative_samples(amount, length, initial_node, number_of_nodes):\n",
    "    negative_samples = torch.zeros((amount, length), dtype=int)\n",
    "    negative_samples[:, 0] = initial_node\n",
    "    negative_samples[:, 1:] = torch.randint(number_of_nodes, (amount, length-1))\n",
    "    return negative_samples\n",
    "\n",
    "gen_negative_samples(amount=3, length=5, initial_node=0, number_of_nodes=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e11f6857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,  375, 1107, 1189,  177],\n",
       "        [   0, 1939,  654, 1437, 1714],\n",
       "        [   0,  680,  120,  157,  405],\n",
       "        [   1, 1432,  519,  618,  886],\n",
       "        [   1,  767,  673,  470, 1023],\n",
       "        [   1,  488, 1946,  355, 1729]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_batch_negative_samples(amount, length, initial_nodes, number_of_nodes):\n",
    "    negative_samples = torch.zeros((amount*initial_nodes.shape[0], length), dtype=int)\n",
    "    negative_samples[:, 0] = initial_nodes.repeat(amount, 1).t().contiguous().view(-1)\n",
    "    negative_samples[:, 1:] = torch.randint(number_of_nodes, (amount*initial_nodes.shape[0], length-1))\n",
    "    return negative_samples\n",
    "\n",
    "gen_batch_negative_samples(amount=3, length=5, initial_nodes=torch.tensor([0, 1]), number_of_nodes=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21b70a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "[40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
      "[60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "[100]\n"
     ]
    }
   ],
   "source": [
    "def generate_batches(array, batch_size):\n",
    "    \"\"\"Yield successive batches of size `batch_size` from `array`.\"\"\"\n",
    "    for i in range(0, len(array), batch_size):\n",
    "        yield array[i:i + batch_size]\n",
    "\n",
    "gen = generate_batches(list(range(101)), 20)\n",
    "for batch in gen:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2ed30782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "eps = 1e-15\n",
    "\n",
    "def deepWalk(graph, walks_per_vertex, walk_length, window_size, embedding_size, num_neg, lr, epochs, batch_size, p = 5, q = 5):\n",
    "    number_of_nodes = graph.number_of_nodes()\n",
    "    \n",
    "    embedding = (torch.randn(size=(number_of_nodes, embedding_size)) ).detach()\n",
    "    embedding.requires_grad = True\n",
    "    optimizer = torch.optim.Adam([embedding], lr=lr)\n",
    "    loss_history = {'pos': [], 'neg': [], 'total': []}\n",
    "    neighbors_dict = {node: list(graph.neighbors(node)) for node in graph.nodes}\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        nodes = torch.tensor(list(graph.nodes), dtype=int)\n",
    "        random.shuffle(nodes)\n",
    "        node_loader = generate_batches(nodes, batch_size)\n",
    "        n_batches = int(number_of_nodes / batch_size)\n",
    "        for n in tqdm(node_loader, total=n_batches):\n",
    "            random_walk = gen_batch_biaised_random_walk(graph, n, walk_length, walks_per_vertex, p, q, neighbors_dict)\n",
    "            num_windows = walk_length + 1 - window_size\n",
    "\n",
    "            # Positive Sampling\n",
    "            # each row of windows is one window, we have B = walks_per_vertex*num_windows windows\n",
    "            windows = generate_windows(random_walk, window_size)\n",
    "            batch_dotproduct = get_windows_dotproduct(windows, embedding)\n",
    "            # takes the sigmoid of the dot product to get probability, then\n",
    "            # takes the loglik and average through all elements\n",
    "            pos_loss = -torch.log(torch.sigmoid(batch_dotproduct)+eps).mean()\n",
    "            # Negative Sampling\n",
    "            negative_samples = gen_batch_negative_samples(\n",
    "                amount=num_neg*walks_per_vertex, \n",
    "                length=walk_length, \n",
    "                initial_nodes=n, \n",
    "                number_of_nodes=number_of_nodes\n",
    "            )\n",
    "            windows = generate_windows(negative_samples, window_size)\n",
    "            batch_dotproduct = get_windows_dotproduct(windows, embedding)\n",
    "            neg_loss = -torch.log(1-torch.sigmoid(batch_dotproduct)+eps).mean()\n",
    "\n",
    "            loss = pos_loss + neg_loss\n",
    "            # Optimization\n",
    "            loss.backward()\n",
    "            loss_history['total'].append(loss.detach().numpy())\n",
    "            loss_history['pos'].append(pos_loss.detach().numpy())\n",
    "            loss_history['neg'].append(neg_loss.detach().numpy())\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()  \n",
    "            break\n",
    "\n",
    "    return embedding, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "38f0c9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/206 [00:24<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         21828400 function calls in 24.726 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    10000   18.819    0.002   24.134    0.002 476093457.py:53(biased_choose_next_node)\n",
      "  5552898    3.309    0.000    4.686    0.000 graph.py:1274(has_edge)\n",
      "  5287657    0.986    0.000    1.377    0.000 _tensor.py:1002(__hash__)\n",
      "  5287659    0.391    0.000    0.391    0.000 {built-in method builtins.id}\n",
      "  5562658    0.385    0.000    0.385    0.000 {method 'append' of 'list' objects}\n",
      "       50    0.231    0.005   24.366    0.487 476093457.py:36(gen_biaised_random_walk_tensor)\n",
      "    10000    0.219    0.000    0.243    0.000 random.py:480(choices)\n",
      "        1    0.142    0.142    0.142    0.142 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
      "        1    0.074    0.074    0.081    0.081 random.py:376(shuffle)\n",
      "        2    0.074    0.037    0.085    0.042 3143600304.py:1(get_windows_dotproduct)\n",
      "        1    0.016    0.016    0.019    0.019 2511371920.py:11(<dictcomp>)\n",
      "    10000    0.011    0.000    0.019    0.000 random.py:514(<listcomp>)\n",
      "        2    0.010    0.005    0.010    0.005 {method 'sum' of 'torch._C._TensorBase' objects}\n",
      "        1    0.006    0.006    0.006    0.006 {built-in method torch.randn}\n",
      "    10000    0.006    0.000    0.006    0.000 {built-in method _bisect.bisect_right}\n",
      "    10311    0.005    0.000    0.006    0.000 random.py:235(_randbelow_with_getrandbits)\n",
      "    20016    0.003    0.000    0.003    0.000 {built-in method builtins.len}\n",
      "    10312    0.003    0.000    0.003    0.000 graph.py:1315(neighbors)\n",
      "    10000    0.003    0.000    0.003    0.000 {method 'random' of '_random.Random' objects}\n",
      "       54    0.003    0.000    0.003    0.000 {built-in method torch.zeros}\n",
      "        1    0.002    0.002   24.726   24.726 <string>:1(<module>)\n",
      "    10000    0.002    0.000    0.002    0.000 {built-in method math.isfinite}\n",
      "        1    0.002    0.002    0.002    0.002 {method 'unbind' of 'torch._C._TensorBase' objects}\n",
      "        1    0.002    0.002    0.006    0.006 adam.py:330(_single_tensor_adam)\n",
      "        2    0.002    0.001    0.002    0.001 {built-in method torch.sigmoid}\n",
      "       31    0.002    0.000    0.002    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        1    0.002    0.002   24.724   24.724 2511371920.py:4(deepWalk)\n",
      "        1    0.001    0.001    0.001    0.001 {method 'lerp_' of 'torch._C._TensorBase' objects}\n",
      "        1    0.001    0.001   24.369   24.369 2239623765.py:1(gen_batch_biaised_random_walk)\n",
      "       11    0.001    0.000    0.001    0.000 socket.py:613(send)\n",
      "        2    0.001    0.001    0.001    0.001 {built-in method torch.log}\n",
      "    15121    0.001    0.000    0.001    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
      "        2    0.001    0.001    0.002    0.001 2214940036.py:1(generate_windows)\n",
      "        2    0.001    0.000    0.001    0.000 {method 'mean' of 'torch._C._TensorBase' objects}\n",
      "        1    0.001    0.001    0.001    0.001 {method 'sqrt' of 'torch._C._TensorBase' objects}\n",
      "        1    0.001    0.001    0.001    0.001 {method 'addcdiv_' of 'torch._C._TensorBase' objects}\n",
      "        2    0.001    0.000    0.001    0.000 {built-in method torch.zeros_like}\n",
      "    10315    0.001    0.000    0.001    0.000 {built-in method builtins.iter}\n",
      "        2    0.001    0.000    0.001    0.000 {built-in method torch.tensor}\n",
      "        1    0.001    0.001    0.001    0.001 {built-in method torch.rsub}\n",
      "    10311    0.001    0.000    0.001    0.000 {method 'bit_length' of 'int' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'addcmul_' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.001    0.001 508423023.py:1(gen_batch_negative_samples)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method nt.stat}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.randint}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'add_' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}\n",
      "       51    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._ops.profiler._record_function_enter_new}\n",
      "        1    0.000    0.000   24.726   24.726 {built-in method builtins.exec}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "        1    0.000    0.000    0.007    0.007 optimizer.py:356(wrapper)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:352(format_meter)\n",
      "        2    0.000    0.000    0.001    0.000 eval_frame.py:267(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._ops.profiler.}\n",
      "        4    0.000    0.000    0.002    0.000 threading.py:604(wait)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:236(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'repeat' of 'torch._C._TensorBase' objects}\n",
      "        4    0.000    0.000    0.001    0.000 iostream.py:534(write)\n",
      "       11    0.000    0.000    0.001    0.000 iostream.py:203(schedule)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:228(_screen_shape_windows)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:48(create_string_buffer)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:846(add_param_group)\n",
      "        4    0.000    0.000    0.002    0.001 iostream.py:479(flush)\n",
      "        1    0.000    0.000    0.002    0.002 std.py:837(__init__)\n",
      "        1    0.000    0.000    0.001    0.001 adam.py:80(_init_group)\n",
      "        2    0.000    0.000    0.000    0.000 1336715503.py:1(generate_batches)\n",
      "        1    0.000    0.000    0.007    0.007 optimizer.py:58(_use_grad)\n",
      "        2    0.000    0.000    0.000    0.000 profiler.py:636(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 _tensor.py:964(__len__)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'detach' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:936(getsourcefile)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "        2    0.000    0.000    0.002    0.001 std.py:1262(close)\n",
      "        4    0.000    0.000    0.002    0.000 threading.py:288(wait)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'numpy' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.142    0.142 __init__.py:149(backward)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:776(zero_grad)\n",
      "        6    0.000    0.000    0.002    0.000 utils.py:125(inner)\n",
      "       80    0.000    0.000    0.000    0.000 utils.py:306(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 eval_frame.py:307(_fn)\n",
      "        5    0.000    0.000    0.000    0.000 std.py:101(acquire)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.006    0.006 adam.py:254(adam)\n",
      "        1    0.000    0.000    0.007    0.007 adam.py:130(step)\n",
      "        2    0.000    0.000    0.000    0.000 optimizer.py:122(<genexpr>)\n",
      "       15    0.000    0.000    0.000    0.000 threading.py:1185(is_alive)\n",
      "        2    0.000    0.000    0.001    0.000 _compile.py:20(inner)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:109(_default_to_fused_or_foreach)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:56(_make_grads)\n",
      "        2    0.000    0.000    0.002    0.001 std.py:1157(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:551(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x00007FFF8C28A4B0}\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:239(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'contiguous' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.001    0.000 decorators.py:33(disable)\n",
      "       30    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        2    0.000    0.000    0.000    0.000 profiler.py:619(__init__)\n",
      "        1    0.000    0.000    0.142    0.142 _tensor.py:433(backward)\n",
      "        1    0.000    0.000    0.001    0.001 std.py:326(status_printer)\n",
      "        5    0.000    0.000    0.000    0.000 std.py:105(release)\n",
      "        4    0.000    0.000    0.000    0.000 utils.py:204(_is_ascii)\n",
      "        2    0.000    0.000    0.000    0.000 functools.py:35(update_wrapper)\n",
      "       11    0.000    0.000    0.000    0.000 iostream.py:90(_event_pipe)\n",
      "        2    0.000    0.000    0.000    0.000 profiler.py:630(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.ones_like}\n",
      "        1    0.000    0.000    0.000    0.000 std.py:574(_decr_instances)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method torch._C._get_tracing_state}\n",
      "       46    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.000    0.000 {method 't' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.001    0.001 _tensor.py:34(wrapped)\n",
      "        2    0.000    0.000    0.002    0.001 std.py:1461(display)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1147(__str__)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:896(getfile)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1443(format_dict)\n",
      "        2    0.000    0.000    0.001    0.000 std.py:1283(fp_write)\n",
      "        2    0.000    0.000    0.002    0.001 std.py:345(print_status)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.sum}\n",
      "        1    0.000    0.000    0.000    0.000 adam.py:15(__init__)\n",
      "       15    0.000    0.000    0.000    0.000 threading.py:1118(_wait_for_tstate_lock)\n",
      "        2    0.000    0.000    0.000    0.000 eval_frame.py:221(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 grad_mode.py:182(__init__)\n",
      "       78    0.000    0.000    0.000    0.000 {built-in method unicodedata.east_asian_width}\n",
      "        2    0.000    0.000    0.000    0.000 eval_frame.py:442(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 iostream.py:443(_is_master_process)\n",
      "        3    0.000    0.000    0.000    0.000 _weakrefset.py:63(__iter__)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:555(__init__)\n",
      "        4    0.000    0.000    0.001    0.000 iostream.py:464(_schedule_flush)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:185(__format__)\n",
      "        2    0.000    0.000    0.000    0.000 _ops.py:447(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:84(_get_value)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:104(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:97(_dispatch_sqrt)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:399(_patch_step_function)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:285(format_interval)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:141(__exit__)\n",
      "       17    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        2    0.000    0.000    0.000    0.000 typing.py:352(inner)\n",
      "        2    0.000    0.000    0.000    0.000 _ops.py:687(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._C._set_grad_enabled}\n",
      "        1    0.000    0.000    0.000    0.000 _foreach_utils.py:14(_get_fused_kernels_supported_devices)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:567(_get_free_pos)\n",
      "        2    0.000    0.000    0.002    0.001 std.py:339(fp_write)\n",
      "        1    0.000    0.000    0.001    0.001 _tensor.py:907(__rsub__)\n",
      "        1    0.000    0.000    0.000    0.000 graph.py:825(number_of_nodes)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:276(_acquire_restore)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:53(_commit_removals)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:267(__exit__)\n",
      "        6    0.000    0.000    0.000    0.000 inspect.py:943(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 package_importer.py:692(_patched_getfile)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:144(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._are_functorch_transforms_active}\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:1446(current_thread)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:309(_cuda_graph_capture_health_check)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}\n",
      "        4    0.000    0.000    0.000    0.000 std.py:109(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:152(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:264(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen genericpath>:16(exists)\n",
      "        1    0.000    0.000    0.000    0.000 _weakrefset.py:110(remove)\n",
      "        1    0.000    0.000    0.002    0.002 _tensor.py:980(__iter__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method utcfromtimestamp}\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:309(disp_len)\n",
      "        4    0.000    0.000    0.000    0.000 eval_frame.py:192(innermost_fn)\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:27(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 functools.py:65(wraps)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'sub' of 're.Pattern' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:305(_text_width)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:287(helper)\n",
      "        1    0.000    0.000    0.000    0.000 _weakrefset.py:85(add)\n",
      "        2    0.000    0.000    0.000    0.000 skipfiles.py:205(check)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method nt.getpid}\n",
      "        4    0.000    0.000    0.000    0.000 std.py:112(__exit__)\n",
      "       16    0.000    0.000    0.000    0.000 threading.py:568(is_set)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method torch._C._dynamo.eval_frame.set_eval_frame}\n",
      "        1    0.000    0.000    0.001    0.001 std.py:1322(refresh)\n",
      "       42    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "       15    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'conj' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "        2    0.000    0.000    0.000    0.000 reportviews.py:185(__iter__)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:83(wrapper_setattr)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:118(disable_on_exception)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:132(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:283(ismodule)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:292(isclass)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:56(__eq__)\n",
      "        6    0.000    0.000    0.000    0.000 inspect.py:946(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:21(__enter__)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method torch.is_grad_enabled}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1207(_handle_fromlist)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:273(_release_save)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._C._get_privateuse1_backend_name}\n",
      "        1    0.000    0.000    0.000    0.000 _monitor.py:94(report)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1154(__hash__)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:197(_supports_unicode)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:279(_is_owned)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "        8    0.000    0.000    0.000    0.000 threading.py:1161(ident)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.is_complex}\n",
      "        4    0.000    0.000    0.000    0.000 utils.py:153(__eq__)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:570(<setcomp>)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1150(_comparable)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:1144(__del__)\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:17(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:378(isfunction)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:230(__call__)\n",
      "        6    0.000    0.000    0.000    0.000 _jit_internal.py:1109(is_scripting)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:183(_is_utf)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:39(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.abs}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:751(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:139(_tensor_or_tensors_to_tuple)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:87(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:466(isframe)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:480(iscode)\n",
      "        2    0.000    0.000    0.000    0.000 adam.py:296(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:43(__format__)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:300(ismethod)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function}\n",
      "        1    0.000    0.000    0.000    0.000 std.py:648(get_lock)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:456(istraceback)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:29(is_built)\n",
      "        2    0.000    0.000    0.000    0.000 decorators.py:141(graph_break)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 std.py:166(colour)\n",
      "        1    0.000    0.000    0.000    0.000 _foreach_utils.py:8(_get_foreach_kernels_supported_devices)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:225(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        4    0.000    0.000    0.000    0.000 _utils.py:841(is_compiling)\n",
      "        2    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}\n",
      "        4    0.000    0.000    0.000    0.000 eval_frame.py:205(enable_dynamic)\n",
      "        4    0.000    0.000    0.000    0.000 eval_frame.py:188(nothing)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:70(__getattr__)\n",
      "        1    0.000    0.000    0.000    0.000 reportviews.py:182(__len__)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:162(colour)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:213(_screen_shape_wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:124(annotate)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:757(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:754(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:340(_optimizer_step_code)\n",
      "        2    0.000    0.000    0.000    0.000 typing.py:2256(cast)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:1298(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method sys.audit}"
     ]
    }
   ],
   "source": [
    "%prun embedding, loss_history = deepWalk(graph=bc_dataset['graph'],  walks_per_vertex=5, walk_length=40, window_size=10,  embedding_size=128,num_neg=5,lr=1e-2,epochs=1,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "584b2bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1243,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cumsum_vec = np.cumsum(np.insert(loss_history['total'], 0, 0)) \n",
    "print(cumsum_vec.shape)\n",
    "window_width = 10\n",
    "ma_vec = (cumsum_vec[window_width:] - cumsum_vec[:-window_width]) / window_width\n",
    "plt.plot(ma_vec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b2255e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex_\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38285492629945694"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = embedding.detach().numpy()\n",
    "y = bc_dataset['labels']\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "y_hat = clf.predict(X)\n",
    "f1_score(y, y_hat, average='micro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
