{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e539cf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/deepmind/jraph.git\n",
      "  Cloning https://github.com/deepmind/jraph.git to c:\\users\\alex_\\appdata\\local\\temp\\pip-req-build-wr8dzk85\n",
      "  Resolved https://github.com/deepmind/jraph.git to commit 51f5990104f7374492f8f3ea1cbc47feb411c69c\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: jax>=0.1.55 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from jraph==0.0.6.dev0) (0.4.23)\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from jraph==0.0.6.dev0) (0.4.23)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from jraph==0.0.6.dev0) (1.26.2)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from jax>=0.1.55->jraph==0.0.6.dev0) (0.3.1)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from jax>=0.1.55->jraph==0.0.6.dev0) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from jax>=0.1.55->jraph==0.0.6.dev0) (1.11.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/deepmind/jraph.git 'C:\\Users\\alex_\\AppData\\Local\\Temp\\pip-req-build-wr8dzk85'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flax in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (0.7.5)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from flax) (1.26.2)\n",
      "Requirement already satisfied: jax>=0.4.19 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from flax) (0.4.23)\n",
      "Requirement already satisfied: msgpack in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from flax) (1.0.7)\n",
      "Requirement already satisfied: optax in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from flax) (0.1.8)\n",
      "Requirement already satisfied: orbax-checkpoint in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from flax) (0.5.1)\n",
      "Requirement already satisfied: tensorstore in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from flax) (0.1.52)\n",
      "Requirement already satisfied: rich>=11.1 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from flax) (13.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from flax) (4.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from flax) (6.0.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from jax>=0.4.19->flax) (0.3.1)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from jax>=0.4.19->flax) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from jax>=0.4.19->flax) (1.11.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from rich>=11.1->flax) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\alex_\\appdata\\roaming\\python\\python311\\site-packages (from rich>=11.1->flax) (2.14.0)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from optax->flax) (2.1.0)\n",
      "Requirement already satisfied: chex>=0.1.7 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from optax->flax) (0.1.85)\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from optax->flax) (0.4.23)\n",
      "Requirement already satisfied: etils[epath,epy] in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from orbax-checkpoint->flax) (1.6.0)\n",
      "Requirement already satisfied: nest_asyncio in c:\\users\\alex_\\appdata\\roaming\\python\\python311\\site-packages (from orbax-checkpoint->flax) (1.5.6)\n",
      "Requirement already satisfied: protobuf in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from orbax-checkpoint->flax) (4.23.4)\n",
      "Requirement already satisfied: toolz>=0.9.0 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from chex>=0.1.7->optax->flax) (0.12.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (2023.12.2)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (6.1.1)\n",
      "Requirement already satisfied: zipp in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (3.17.0)\n",
      "Requirement already satisfied: dm-haiku in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (0.0.12)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from dm-haiku) (2.1.0)\n",
      "Requirement already satisfied: jmp>=0.0.2 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from dm-haiku) (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from dm-haiku) (1.26.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from dm-haiku) (0.9.0)\n",
      "Requirement already satisfied: flax>=0.7.1 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from dm-haiku) (0.7.5)\n",
      "Requirement already satisfied: jax>=0.4.19 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from flax>=0.7.1->dm-haiku) (0.4.23)\n",
      "Requirement already satisfied: msgpack in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from flax>=0.7.1->dm-haiku) (1.0.7)\n",
      "Requirement already satisfied: optax in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from flax>=0.7.1->dm-haiku) (0.1.8)\n",
      "Requirement already satisfied: orbax-checkpoint in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from flax>=0.7.1->dm-haiku) (0.5.1)\n",
      "Requirement already satisfied: tensorstore in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from flax>=0.7.1->dm-haiku) (0.1.52)\n",
      "Requirement already satisfied: rich>=11.1 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from flax>=0.7.1->dm-haiku) (13.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from flax>=0.7.1->dm-haiku) (4.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from flax>=0.7.1->dm-haiku) (6.0.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from jax>=0.4.19->flax>=0.7.1->dm-haiku) (0.3.1)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from jax>=0.4.19->flax>=0.7.1->dm-haiku) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from jax>=0.4.19->flax>=0.7.1->dm-haiku) (1.11.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from rich>=11.1->flax>=0.7.1->dm-haiku) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\alex_\\appdata\\roaming\\python\\python311\\site-packages (from rich>=11.1->flax>=0.7.1->dm-haiku) (2.14.0)\n",
      "Requirement already satisfied: chex>=0.1.7 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from optax->flax>=0.7.1->dm-haiku) (0.1.85)\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from optax->flax>=0.7.1->dm-haiku) (0.4.23)\n",
      "Requirement already satisfied: etils[epath,epy] in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from orbax-checkpoint->flax>=0.7.1->dm-haiku) (1.6.0)\n",
      "Requirement already satisfied: nest_asyncio in c:\\users\\alex_\\appdata\\roaming\\python\\python311\\site-packages (from orbax-checkpoint->flax>=0.7.1->dm-haiku) (1.5.6)\n",
      "Requirement already satisfied: protobuf in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from orbax-checkpoint->flax>=0.7.1->dm-haiku) (4.23.4)\n",
      "Requirement already satisfied: toolz>=0.9.0 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from chex>=0.1.7->optax->flax>=0.7.1->dm-haiku) (0.12.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.1->dm-haiku) (0.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.1->dm-haiku) (2023.12.2)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.1->dm-haiku) (6.1.1)\n",
      "Requirement already satisfied: zipp in c:\\users\\alex_\\anaconda3\\envs\\jax_env\\lib\\site-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.1->dm-haiku) (3.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/deepmind/jraph.git\n",
    "!pip install flax\n",
    "!pip install dm-haiku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10b307a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit\n",
    "import jax.tree_util as tree\n",
    "import jraph\n",
    "import flax\n",
    "import haiku as hk\n",
    "import optax\n",
    "import pickle\n",
    "import numpy as onp\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pickle as p\n",
    "from os import path\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from jax import random as jrandom\n",
    "from functools import partial\n",
    "\n",
    "data_loc = 'C:/Users/alex_/Fac/M2/M2/S2/Discrete_Graphs/Projet/Data/BlogCatalog3/BlogCatalog-dataset/data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f72e4",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07063a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:  [10312]\n",
      "Number of edges:  [333983]\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    iid = {}\n",
    "    idx = 0\n",
    "    sender_list = []  # List to store sender indices\n",
    "    receiver_list = []  # List to store receiver indices\n",
    "\n",
    "    # Read edges pairs\n",
    "    with open(data_loc+'edges.csv', 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            i, j = line.strip().split(',')  # csv\n",
    "            if i not in iid:\n",
    "                iid[i] = idx; idx += 1\n",
    "            if j not in iid:\n",
    "                iid[j] = idx; idx += 1\n",
    "            sender_list.append(iid[i])  # Append sender index\n",
    "            receiver_list.append(iid[j])  # Append receiver index\n",
    "            \n",
    "            # Add the reverse edge as well\n",
    "            sender_list.append(iid[j])  # Append sender index\n",
    "            receiver_list.append(iid[i])  # Append receiver index\n",
    "\n",
    "    sender_array = jnp.array(sender_list)\n",
    "    receiver_array = jnp.array(receiver_list)\n",
    "    n_node = jnp.array([jnp.unique(sender_array).size])\n",
    "    n_edge = jnp.array([len(sender_list) // 2])\n",
    "\n",
    "    print(\"Number of nodes: \", n_node)\n",
    "    print(\"Number of edges: \", n_edge)\n",
    "\n",
    "    # Read labels\n",
    "    labels = jnp.zeros((n_node), dtype=int)\n",
    "    # Read (node_id, label) file\n",
    "    with open(data_loc+'group-edges.csv', 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            node, group = line.strip().split(',') \n",
    "            labels = labels.at[iid[node]].set(int(group) - 1)\n",
    "\n",
    "    graph = jraph.GraphsTuple(\n",
    "      nodes=labels,\n",
    "      edges = None,\n",
    "      senders=sender_array,\n",
    "      receivers=receiver_array,\n",
    "      n_node=n_node,\n",
    "      n_edge=n_edge,\n",
    "      globals = None)\n",
    "    #bc_dataset = {'graph': graph, 'labels': labels}\n",
    "    return graph\n",
    "\n",
    "bc_dataset = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee578691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([333983], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_dataset.n_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2746511e",
   "metadata": {},
   "source": [
    "## Visualizing the Graph\n",
    "To visualize the graph structure of the graph we created above, we will use the [`networkx`](networkx.org) library because it already has functions for drawing graphs.\n",
    "\n",
    "We first convert the `jraph.GraphsTuple` to a `networkx.DiGraph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "921215e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_jraph_to_networkx_graph(jraph_graph: jraph.GraphsTuple) -> nx.Graph:\n",
    "  nodes, edges, receivers, senders, _, _, _ = jraph_graph\n",
    "  nx_graph = nx.DiGraph()\n",
    "  if nodes is None:\n",
    "    for n in range(jraph_graph.n_node[0]):\n",
    "      nx_graph.add_node(n)\n",
    "  else:\n",
    "    for n in range(jraph_graph.n_node[0]):\n",
    "      nx_graph.add_node(n, node_feature=nodes[n])\n",
    "  if edges is None:\n",
    "    i = 0\n",
    "    print(jraph_graph.n_edge[0])\n",
    "    for e in range(jraph_graph.n_edge[0]):\n",
    "      if i%10000 == 0:\n",
    "        print(i)\n",
    "      i +=1\n",
    "      nx_graph.add_edge(int(senders[e]), int(receivers[e]))\n",
    "  else:\n",
    "    for e in range(jraph_graph.n_edge[0]):\n",
    "      nx_graph.add_edge(\n",
    "          int(senders[e]), int(receivers[e]), edge_feature=edges[e])\n",
    "  return nx_graph\n",
    "\n",
    "\n",
    "def draw_jraph_graph_structure(jraph_graph: jraph.GraphsTuple) -> None:\n",
    "  nx_graph = convert_jraph_to_networkx_graph(jraph_graph)\n",
    "  pos = nx.spring_layout(nx_graph)\n",
    "  nx.draw(\n",
    "      nx_graph, pos=pos, with_labels=True, node_size=500, font_color='yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13deacf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The graph is too big to be displayed\n",
    "#draw_jraph_graph_structure(bc_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e5baaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "38\n",
      "[[   0   60]\n",
      " [   1  488]\n",
      " [   2  365]\n",
      " [   3  119]\n",
      " [   4  625]\n",
      " [   5  563]\n",
      " [   6  393]\n",
      " [   7 1076]\n",
      " [   8  247]\n",
      " [   9  300]\n",
      " [  10  325]\n",
      " [  11   25]\n",
      " [  12   35]\n",
      " [  13  239]\n",
      " [  14   53]\n",
      " [  15  295]\n",
      " [  16  351]\n",
      " [  17  236]\n",
      " [  18  715]\n",
      " [  19  247]\n",
      " [  20  228]\n",
      " [  21  233]\n",
      " [  22  279]\n",
      " [  23  846]\n",
      " [  24  170]\n",
      " [  25  242]\n",
      " [  26   88]\n",
      " [  27   85]\n",
      " [  28  155]\n",
      " [  29  360]\n",
      " [  30   62]\n",
      " [  31  371]\n",
      " [  32   91]\n",
      " [  33   62]\n",
      " [  34   58]\n",
      " [  35  137]\n",
      " [  36   53]\n",
      " [  37   27]\n",
      " [  38    8]]\n"
     ]
    }
   ],
   "source": [
    "print(jnp.min(bc_dataset.nodes))\n",
    "print(jnp.max(bc_dataset.nodes))\n",
    "unique, counts = jnp.unique(bc_dataset.nodes, return_counts=True)\n",
    "print(jnp.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82ae8b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_random_walk_tensor(walk, graph , node, length, num_walks, rng_key):\n",
    "    walk = jnp.zeros((num_walks, length), dtype=jnp.int32)\n",
    "    walk = walk.at[:, 0].set(node)\n",
    "    j = 0\n",
    "    while j < num_walks:\n",
    "        current_node = node\n",
    "        step = 1\n",
    "        while step < length:\n",
    "            outgoing_edges = jnp.where(graph.senders == current_node)[0]\n",
    "            # Extraire les nœuds destinataires des arêtes sortantes\n",
    "            neighbors = jnp.take(graph.receivers, outgoing_edges)\n",
    "            rng_key, subkey = jrandom.split(rng_key)\n",
    "            current_node = jrandom.choice(subkey, neighbors)\n",
    "            walk = walk.at[j, step].set(current_node)\n",
    "            step += 1\n",
    "        j += 1\n",
    "    return walk, rng_key\n",
    "\n",
    "# Assert all edges exist\n",
    "num_walks = 5\n",
    "length = 5\n",
    "rng_key = jrandom.key(1)\n",
    "walk = jnp.zeros((num_walks, length), dtype=jnp.int32)\n",
    "\n",
    "rws, rng_key = gen_random_walk_tensor(walk,bc_dataset, 0, 5, 5,rng_key)\n",
    "for walk in range(5):\n",
    "    rw = rws[walk]\n",
    "    for step in range(4):\n",
    "        edge_exists = jnp.any(jnp.logical_and(bc_dataset.senders == rw[step], bc_dataset.receivers == rw[step+1]))\n",
    "        assert edge_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57ec5c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   91 1066 1298   40]\n",
      " [   0  101  363 3063 2255]\n",
      " [   0  103 1138  296  203]]\n"
     ]
    }
   ],
   "source": [
    "rws, rng_key = gen_random_walk_tensor(walk,bc_dataset, 0, 5, 3,rng_key)\n",
    "print(rws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3916250f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    3  461 5583  246]\n",
      " [   0   43 4367    9 3677]\n",
      " [   0   80 3590    8 7455]\n",
      " [   1  161  617 3846  166]\n",
      " [   1 3115   25 3082   12]\n",
      " [   1 2172   76 4535 6754]]\n"
     ]
    }
   ],
   "source": [
    "def gen_batch_random_walk(batch_walk, graph, initial_nodes, length, num_walks, rng_key):\n",
    "    n_nodes = initial_nodes.shape[0]\n",
    "    walk = jnp.zeros((num_walks, length), dtype=jnp.int32)\n",
    "    batch_walk = jnp.zeros((num_walks * n_nodes, length), dtype=jnp.int32)\n",
    "    for i, n in enumerate(initial_nodes):\n",
    "        n = n.item()\n",
    "        rng_key, subkey = jrandom.split(rng_key)\n",
    "        sub_walk, rng_key = gen_random_walk_tensor(walk, graph, n, length, num_walks, subkey)\n",
    "        batch_walk = batch_walk.at[num_walks * i:num_walks * (i + 1)].set(sub_walk)\n",
    "    return walk, batch_walk , rng_key\n",
    "\n",
    "rng_key = jrandom.key(0)\n",
    "last_walk, batch_walk, rng_key = gen_batch_random_walk(walk, bc_dataset, jnp.array([0, 1]), 5, 3, rng_key)\n",
    "print(batch_walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7eda3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5)\n",
      "(18, 3)\n"
     ]
    }
   ],
   "source": [
    "def generate_windows(windows, random_walk, window_size):\n",
    "    num_walks, walk_length = random_walk.shape\n",
    "    num_windows = walk_length + 1 - window_size\n",
    "    windows = jnp.zeros((num_walks * num_windows, window_size), dtype=jnp.int32)\n",
    "    for j in range(num_windows):\n",
    "        windows = windows.at[num_walks * j:num_walks * (j + 1)].set(random_walk[:, j:j + window_size])\n",
    "    return windows\n",
    "\n",
    "windows = jnp.zeros((1,1), dtype=int)\n",
    "windows = generate_windows(windows,batch_walk, 3)\n",
    "print(batch_walk.shape)\n",
    "print(windows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39e0c029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[  9.989289 ,  14.355413 ],\n",
       "       [  0.1050415,  -8.012434 ],\n",
       "       [  8.171717 ,  22.485273 ],\n",
       "       [-14.368268 ,  19.513103 ],\n",
       "       [ -4.4057875,  -8.634464 ],\n",
       "       [-10.255943 ,   3.4406242],\n",
       "       [-11.403227 , -12.996876 ],\n",
       "       [ -1.2675204,  17.343775 ],\n",
       "       [ -6.70873  ,  -7.203182 ],\n",
       "       [-19.548515 ,  23.787937 ],\n",
       "       [  8.799166 ,  29.117088 ],\n",
       "       [-23.854403 ,  -1.1407938],\n",
       "       [ 37.785007 , -10.838488 ],\n",
       "       [  9.711828 , -32.64926  ],\n",
       "       [ -3.9425344,   1.5056596],\n",
       "       [-11.72566  ,  11.133398 ],\n",
       "       [  5.2066326, -15.35693  ],\n",
       "       [ -1.85783  , -27.490053 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jit\n",
    "def get_windows_dotproduct(windows, embedding):\n",
    "    embedding_size = embedding.shape[1]\n",
    "    # get the embedding of the initial node repeated num_windows times\n",
    "    first_emb = embedding[windows[:, 0]]\n",
    "    first_emb = jnp.expand_dims(first_emb, axis=1)  # Ajouter une nouvelle dimension\n",
    "    # get the embedding of the remaining nodes in each window\n",
    "    others_emb = embedding[windows[:, 1:]]\n",
    "    others_emb = others_emb.reshape(windows.shape[0], -1, embedding_size)\n",
    "    # result has same shape as others\n",
    "    # Each element is the dot product between the corresponding node embedding\n",
    "    # and the embedding of the first node of that walk\n",
    "    # that is, result_{i, j} for random walk i and element j is v_{W_{i, 0}} dot v_{W_{i, j}}\n",
    "    result = jnp.sum(first_emb * others_emb, axis=-1)\n",
    "    return result\n",
    "\n",
    "embedding_jax = jax.random.normal(rng_key, shape=(12000, 300))\n",
    "get_windows_dotproduct(windows, embedding_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cb5b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def compute_mean_log_sigmoid(windows, embedding):\n",
    "    dot_product = get_windows_dotproduct(windows, embedding)\n",
    "    sigmoid_output = 1 / (1 + jnp.exp(-dot_product))  # Sigmoid function\n",
    "    log_sigmoid_output = jnp.log(sigmoid_output)  # Logarithm\n",
    "    return jnp.mean(log_sigmoid_output)  # Mean\n",
    "\n",
    "# Usage example:\n",
    "mean_log_sigmoid = compute_mean_log_sigmoid(windows, embedding_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72c69545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[   0,  825,  911, 1631, 1314],\n",
       "        [   0,   28, 1399, 1362,  613],\n",
       "        [   0, 1806,  630, 1652,  360]], dtype=int32),\n",
       " Array((), dtype=key<fry>) overlaying:\n",
       " [3000548268 4272618543])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_negative_samples(amount, length, initial_node, number_of_nodes,rng_key):\n",
    "  \"\"\"Generates negative samples for a random walk process in JAX.\n",
    "\n",
    "  Args:\n",
    "    amount: Number of negative samples to generate.\n",
    "    length: Length of each negative sample walk (number of nodes in the path).\n",
    "    initial_node: Starting node for all negative samples.\n",
    "    number_of_nodes: Total number of nodes in the graph.\n",
    "\n",
    "  Returns:\n",
    "    A JAX array of shape (amount, length) containing the negative samples.\n",
    "  \"\"\"\n",
    "  negative_samples = jnp.zeros((amount, length), dtype=jnp.int32)  # Use jnp.int32 for node indices\n",
    "  negative_samples = negative_samples.at[:, 0].set(initial_node)  # Set initial node efficiently\n",
    "  rng_key, subkey = jrandom.split(rng_key)\n",
    "  negative_samples = negative_samples.at[:, 1:].set(\n",
    "      jrandom.randint(rng_key,shape=(amount, length - 1),minval = 0, maxval = number_of_nodes)\n",
    "  )\n",
    "  return negative_samples, rng_key\n",
    "\n",
    "gen_negative_samples(amount=3, length=5, initial_node=0, number_of_nodes=2000,rng_key =rng_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8fdede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 1180 1940  427  957]\n",
      " [   0 1528 1469  905   90]\n",
      " [   0 1610  587  474  515]\n",
      " [   1 1402   71 1354 1003]\n",
      " [   1  205 1527 1098  918]\n",
      " [   1  859 1883 1862 1594]]\n"
     ]
    }
   ],
   "source": [
    "def gen_batch_negative_samples(amount, length, initial_nodes, number_of_nodes,rng_key):\n",
    "  \"\"\"Generates negative samples for a random walk process in JAX for a batch of initial nodes.\n",
    "\n",
    "  Args:\n",
    "    amount: Number of negative samples to generate per initial node.\n",
    "    length: Length of each negative sample walk (number of nodes in the path).\n",
    "    initial_nodes: A JAX array of shape (batch_size,) containing initial nodes for each sample.\n",
    "    number_of_nodes: Total number of nodes in the graph.\n",
    "\n",
    "  Returns:\n",
    "    A JAX array of shape (amount * batch_size, length) containing the negative samples.\n",
    "  \"\"\"\n",
    "\n",
    "  # Expand initial_nodes to match amount (amount, batch_size)\n",
    "  #initial_nodes = jnp.expand_dims(initial_nodes, axis=0).repeat(amount, axis=0)\n",
    "  n_nodes = initial_nodes.shape[0]\n",
    "  num_walks = amount\n",
    "  sub_negative_sample = jnp.zeros((num_walks, length), dtype=jnp.int32)\n",
    "  batch_negative_sample = jnp.zeros((num_walks * n_nodes, length), dtype=jnp.int32)\n",
    "  for i, n in enumerate(initial_nodes):\n",
    "      n = n.item()\n",
    "      rng_key, subkey = jrandom.split(rng_key)\n",
    "      sub_negative_sample, rng_key = gen_negative_samples(amount, length, n, number_of_nodes, subkey)\n",
    "      batch_negative_sample = batch_negative_sample.at[amount * i:amount * (i + 1)].set(sub_negative_sample)\n",
    "  return batch_negative_sample , rng_key\n",
    "\n",
    "\n",
    "# Example usage\n",
    "initial_nodes = jnp.array([0, 1])\n",
    "a, b =gen_batch_negative_samples(amount=3, length=5, initial_nodes=initial_nodes, number_of_nodes=2000,rng_key = rng_key)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d351cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "[40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
      "[60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "[100]\n"
     ]
    }
   ],
   "source": [
    "def generate_batches(array, batch_size):\n",
    "    \"\"\"Yield successive batches of size `batch_size` from `array`.\"\"\"\n",
    "    for i in range(0, len(array), batch_size):\n",
    "        yield array[i:i + batch_size]\n",
    "\n",
    "gen = generate_batches(list(range(101)), 20)\n",
    "for batch in gen:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c04a7166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "eps = 1e-15\n",
    "\n",
    "def deepWalk(graph, walks_per_vertex, walk_length, window_size, embedding_size, num_neg, lr, epochs, batch_size):\n",
    "    number_of_nodes = jnp.array([jnp.unique(graph.senders).size])\n",
    "    \n",
    "    embedding = (torch.randn(size=(number_of_nodes, embedding_size)))\n",
    "    embedding = jax.random.normal(rng_key, shape=(number_of_nodes, embedding_size))\n",
    "    embedding.requires_grad = True\n",
    "    optimizer = torch.optim.SGD([embedding], lr=lr)\n",
    "    loss_history = {'pos': [], 'neg': [], 'total': []}\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        nodes = torch.tensor(list(graph.nodes), dtype=int)\n",
    "        random.shuffle(nodes)\n",
    "        node_loader = generate_batches(nodes, batch_size)\n",
    "        n_batches = int(number_of_nodes / batch_size)\n",
    "        for n in tqdm(node_loader, total=n_batches):\n",
    "            random_walk = gen_batch_random_walk(graph, n, walk_length, walks_per_vertex)\n",
    "            num_windows = walk_length + 1 - window_size\n",
    "\n",
    "            # Positive Sampling\n",
    "            # each row of windows is one window, we have B = walks_per_vertex*num_windows windows\n",
    "            windows = generate_windows(random_walk, window_size)\n",
    "            batch_dotproduct = get_windows_dotproduct(windows, embedding)\n",
    "            # takes the sigmoid of the dot product to get probability, then\n",
    "            # takes the loglik and average through all elements\n",
    "            pos_loss = -torch.log(torch.sigmoid(batch_dotproduct)+eps).mean()\n",
    "            # Negative Sampling\n",
    "            negative_samples = gen_batch_negative_samples(\n",
    "                amount=num_neg*walks_per_vertex, \n",
    "                length=walk_length, \n",
    "                initial_nodes=n, \n",
    "                number_of_nodes=number_of_nodes\n",
    "            )\n",
    "            windows = generate_windows(negative_samples, window_size)\n",
    "            batch_dotproduct = get_windows_dotproduct(windows, embedding)\n",
    "            neg_loss = -torch.log(1-torch.sigmoid(batch_dotproduct)+eps).mean()\n",
    "\n",
    "            loss = pos_loss + neg_loss\n",
    "            # Optimization\n",
    "            loss.backward()\n",
    "            loss_history['total'].append(loss.detach().numpy())\n",
    "            loss_history['pos'].append(pos_loss.detach().numpy())\n",
    "            loss_history['neg'].append(neg_loss.detach().numpy())\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()  \n",
    "\n",
    "    return embedding, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb3aa121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import optax\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "### TO FIX\n",
    "\n",
    "def deepWalk(graph, walks_per_vertex, walk_length, window_size, embedding_size, num_neg, lr, epochs, batch_size,rng_key ,eps = 1e-15):\n",
    "    \n",
    "    number_of_nodes = int(jnp.unique(graph.senders).size)\n",
    "    \n",
    "    embedding = jax.random.normal(rng_key, shape=(number_of_nodes, embedding_size))\n",
    "    optimizer = optax.sgd(learning_rate=lr)\n",
    "    opt_state = optimizer.init(embedding)\n",
    "    loss_history = {'pos': [], 'neg': [], 'total': []}\n",
    "\n",
    "    def loss_fn(batch_dotproduct_positive, batch_dotproduct_negative, eps = 1e-8):\n",
    "        pos_loss = -jnp.log(jax.nn.sigmoid(batch_dotproduct_positive) + eps).mean()\n",
    "        print(\"test\")\n",
    "        neg_loss = -jnp.log(1 - jax.nn.sigmoid(batch_dotproduct_negative) + eps).mean()\n",
    "        print(\"essai\")\n",
    "        return pos_loss + neg_loss\n",
    "    \n",
    "    def update(params, opt_state, batch_dotproduct_positive, batch_dotproduct_negative):\n",
    "        grad_fn = jax.value_and_grad(loss_fn)\n",
    "        loss, grads = grad_fn(batch_dotproduct_positive, batch_dotproduct_negative)\n",
    "        updates, opt_state = optimizer.update(grads, opt_state)\n",
    "        new_params = optax.apply_updates(params, updates)\n",
    "        return new_params, opt_state, loss\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        nodes = jnp.array(list(graph.nodes), dtype=jnp.int32)\n",
    "        nodes = jax.random.permutation(rng_key, nodes)\n",
    "        node_loader = generate_batches(nodes, batch_size)\n",
    "        n_batches = int(number_of_nodes / batch_size)\n",
    "        batch_walk = 0\n",
    "        for n in tqdm(node_loader, total=n_batches):\n",
    "            walk, batch_walk , rng_key = gen_batch_random_walk(batch_walk, graph, n, walk_length, walks_per_vertex, rng_key)\n",
    "            batch_negative_sample , rng_key = gen_batch_negative_samples(\n",
    "                amount=num_neg * walks_per_vertex, \n",
    "                length=walk_length, \n",
    "                initial_nodes=n, \n",
    "                number_of_nodes=number_of_nodes,\n",
    "                rng_key = rng_key\n",
    "            )\n",
    "            windows = 0\n",
    "            windows = generate_windows(windows, batch_walk, window_size)\n",
    "            batch_dotproduct_positive = get_windows_dotproduct(windows, embedding)\n",
    "            windows = generate_windows(windows,batch_negative_sample, window_size)\n",
    "            batch_dotproduct_negative = get_windows_dotproduct(windows, embedding)\n",
    "\n",
    "            embedding, opt_state, loss = update(embedding, opt_state, batch_dotproduct_positive, batch_dotproduct_negative)\n",
    "            loss_history['total'].append(loss)\n",
    "\n",
    "    return embedding, loss_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d6d17aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "essai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "add got incompatible shapes for broadcasting: (10312, 128), (512, 0).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m embedding, loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mdeepWalk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbc_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwalks_per_vertex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwalk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_neg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.011\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrng_key\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[58], line 54\u001b[0m, in \u001b[0;36mdeepWalk\u001b[1;34m(graph, walks_per_vertex, walk_length, window_size, embedding_size, num_neg, lr, epochs, batch_size, rng_key, eps)\u001b[0m\n\u001b[0;32m     51\u001b[0m         windows \u001b[38;5;241m=\u001b[39m generate_windows(windows,batch_negative_sample, window_size)\n\u001b[0;32m     52\u001b[0m         batch_dotproduct_negative \u001b[38;5;241m=\u001b[39m get_windows_dotproduct(windows, embedding)\n\u001b[1;32m---> 54\u001b[0m         embedding, opt_state, loss \u001b[38;5;241m=\u001b[39m \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dotproduct_positive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dotproduct_negative\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m         loss_history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embedding, loss_history\n",
      "Cell \u001b[1;32mIn[58], line 30\u001b[0m, in \u001b[0;36mdeepWalk.<locals>.update\u001b[1;34m(params, opt_state, batch_dotproduct_positive, batch_dotproduct_negative)\u001b[0m\n\u001b[0;32m     28\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m grad_fn(batch_dotproduct_positive, batch_dotproduct_negative)\n\u001b[0;32m     29\u001b[0m updates, opt_state \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mupdate(grads, opt_state)\n\u001b[1;32m---> 30\u001b[0m new_params \u001b[38;5;241m=\u001b[39m \u001b[43moptax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_updates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_params, opt_state, loss\n",
      "File \u001b[1;32mc:\\Users\\alex_\\anaconda3\\envs\\jax_env\\Lib\\site-packages\\optax\\_src\\update.py:42\u001b[0m, in \u001b[0;36mapply_updates\u001b[1;34m(params, updates)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_updates\u001b[39m(params: base\u001b[38;5;241m.\u001b[39mParams, updates: base\u001b[38;5;241m.\u001b[39mUpdates) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m base\u001b[38;5;241m.\u001b[39mParams:\n\u001b[0;32m     25\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Applies an update to the corresponding parameters.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m  This is a utility functions that applies an update to a set of parameters, and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    Updated parameters, with same structure, shape and type as `params`.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdates\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alex_\\anaconda3\\envs\\jax_env\\Lib\\site-packages\\jax\\_src\\tree_util.py:244\u001b[0m, in \u001b[0;36mtree_map\u001b[1;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[0;32m    242\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[0;32m    243\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[1;32m--> 244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreedef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_leaves\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alex_\\anaconda3\\envs\\jax_env\\Lib\\site-packages\\jax\\_src\\tree_util.py:244\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    242\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[0;32m    243\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[1;32m--> 244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "File \u001b[1;32mc:\\Users\\alex_\\anaconda3\\envs\\jax_env\\Lib\\site-packages\\optax\\_src\\update.py:43\u001b[0m, in \u001b[0;36mapply_updates.<locals>.<lambda>\u001b[1;34m(p, u)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_updates\u001b[39m(params: base\u001b[38;5;241m.\u001b[39mParams, updates: base\u001b[38;5;241m.\u001b[39mUpdates) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m base\u001b[38;5;241m.\u001b[39mParams:\n\u001b[0;32m     25\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Applies an update to the corresponding parameters.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m  This is a utility functions that applies an update to a set of parameters, and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    Updated parameters, with same structure, shape and type as `params`.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m     42\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_map(\n\u001b[1;32m---> 43\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m p, u: jnp\u001b[38;5;241m.\u001b[39masarray(\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m)\u001b[38;5;241m.\u001b[39mastype(jnp\u001b[38;5;241m.\u001b[39masarray(p)\u001b[38;5;241m.\u001b[39mdtype),\n\u001b[0;32m     44\u001b[0m       params, updates)\n",
      "File \u001b[1;32mc:\\Users\\alex_\\anaconda3\\envs\\jax_env\\Lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:271\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    269\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[1;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[1;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\alex_\\anaconda3\\envs\\jax_env\\Lib\\site-packages\\jax\\_src\\numpy\\ufuncs.py:99\u001b[0m, in \u001b[0;36m_maybe_bool_binop.<locals>.fn\u001b[1;34m(x1, x2)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(x1, x2, \u001b[38;5;241m/\u001b[39m):\n\u001b[0;32m     98\u001b[0m   x1, x2 \u001b[38;5;241m=\u001b[39m promote_args(numpy_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, x1, x2)\n\u001b[1;32m---> 99\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlax_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m x1\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_ \u001b[38;5;28;01melse\u001b[39;00m bool_lax_fn(x1, x2)\n",
      "    \u001b[1;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\alex_\\anaconda3\\envs\\jax_env\\Lib\\site-packages\\jax\\_src\\lax\\lax.py:1599\u001b[0m, in \u001b[0;36mbroadcasting_shape_rule\u001b[1;34m(name, *avals)\u001b[0m\n\u001b[0;32m   1597\u001b[0m       result_shape\u001b[38;5;241m.\u001b[39mappend(non_1s[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1599\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m got incompatible shapes for broadcasting: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1600\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mtuple\u001b[39m,\u001b[38;5;250m \u001b[39mshapes)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(result_shape)\n",
      "\u001b[1;31mTypeError\u001b[0m: add got incompatible shapes for broadcasting: (10312, 128), (512, 0)."
     ]
    }
   ],
   "source": [
    "embedding, loss_history = deepWalk(\n",
    "    graph=bc_dataset,  \n",
    "    walks_per_vertex=1, \n",
    "    walk_length=2, \n",
    "    window_size=1,  \n",
    "    embedding_size=128,\n",
    "    num_neg=2,\n",
    "    lr=0.011,\n",
    "    epochs=1,\n",
    "    batch_size=256,\n",
    "    rng_key = rng_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "584b2bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d4e4e6b890>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cumsum_vec = np.cumsum(np.insert(loss_history['total'], 0, 0)) \n",
    "window_width = 10\n",
    "ma_vec = (cumsum_vec[window_width:] - cumsum_vec[:-window_width]) / window_width\n",
    "plt.plot(ma_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c223f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92f12ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = (X-X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2255e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = embedding.detach().numpy()\n",
    "y = bc_dataset['labels']\n",
    "\n",
    "clf = LogisticRegression(random_state=0, multi_class='ovr').fit(X_norm, y)\n",
    "y_hat = clf.predict(X_norm)\n",
    "f1_score(y, y_hat, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cffcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_t = pca.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c6ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_t[:, 0], X_t[:, 1], c=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
