{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "10b307a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pickle as p\n",
    "from os import path\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "\n",
    "data_loc = './BlogCatalog3/BlogCatalog-dataset/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba68a41f",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "07063a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:  10312\n",
      "Number of edges:  333983\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    iid = {}\n",
    "    idx = 0\n",
    "    edgelist = []\n",
    "\n",
    "    # Read edges pairs\n",
    "    with open(data_loc+'edges.csv', 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            i, j = line.strip().split(',')  # csv\n",
    "            if i not in iid:\n",
    "                iid[i] = idx; idx += 1\n",
    "            if j not in iid:\n",
    "                iid[j] = idx; idx += 1\n",
    "            edgelist.append((iid[i], iid[j]))\n",
    "\n",
    "    # Create an nx undirected network\n",
    "    bc = nx.Graph(edgelist)\n",
    "\n",
    "    print(\"Number of nodes: \", len(bc))\n",
    "    print(\"Number of edges: \", bc.size())\n",
    "\n",
    "    # Read labels\n",
    "    labels = np.zeros((len(bc)), dtype=int)\n",
    "    # Read (node_id, label) file\n",
    "    with open(data_loc+'group-edges.csv', 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            node, group = line.strip().split(',') \n",
    "            labels[iid[node]] = int(group)-1  \n",
    "\n",
    "    bc_dataset = {'graph': bc, 'labels': labels}\n",
    "    return bc_dataset\n",
    "\n",
    "bc_dataset = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e5baaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "38\n",
      "[[   0   60]\n",
      " [   1  488]\n",
      " [   2  365]\n",
      " [   3  119]\n",
      " [   4  625]\n",
      " [   5  563]\n",
      " [   6  393]\n",
      " [   7 1076]\n",
      " [   8  247]\n",
      " [   9  300]\n",
      " [  10  325]\n",
      " [  11   25]\n",
      " [  12   35]\n",
      " [  13  239]\n",
      " [  14   53]\n",
      " [  15  295]\n",
      " [  16  351]\n",
      " [  17  236]\n",
      " [  18  715]\n",
      " [  19  247]\n",
      " [  20  228]\n",
      " [  21  233]\n",
      " [  22  279]\n",
      " [  23  846]\n",
      " [  24  170]\n",
      " [  25  242]\n",
      " [  26   88]\n",
      " [  27   85]\n",
      " [  28  155]\n",
      " [  29  360]\n",
      " [  30   62]\n",
      " [  31  371]\n",
      " [  32   91]\n",
      " [  33   62]\n",
      " [  34   58]\n",
      " [  35  137]\n",
      " [  36   53]\n",
      " [  37   27]\n",
      " [  38    8]]\n"
     ]
    }
   ],
   "source": [
    "print(np.min(bc_dataset['labels']))\n",
    "print(np.max(bc_dataset['labels']))\n",
    "unique, counts = np.unique(bc_dataset['labels'], return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "82ae8b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1, 4941,    1, 4941,    1],\n",
       "        [   1, 3276,    1, 3276,    1],\n",
       "        [   1, 2152,    1, 2152,    1]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def gen_biaised_random_walk_tensor(graph, start_node, walk_length, num_walks, p, q):\n",
    "    walk = torch.zeros((num_walks, walk_length), dtype=int)\n",
    "    walk[:, 0] = start_node\n",
    "    j = 0\n",
    "    while j < num_walks:\n",
    "        current_node = start_node\n",
    "        step = 1\n",
    "        while step < walk_length:\n",
    "            neighbors = list(graph.neighbors(current_node))\n",
    "            if step == 1:\n",
    "                current_node = random.choice(neighbors)\n",
    "            else:\n",
    "                prev_node = walk[j,step-1]\n",
    "                current_node = biased_choose_next_node(graph, current_node, prev_node, p, q)\n",
    "            walk[j, step] = current_node\n",
    "            step += 1\n",
    "        j+=1\n",
    "    return walk\n",
    "\n",
    "\n",
    "def biased_choose_next_node(graph, current_node, prev_node, p, q):\n",
    "    neighbors = list(graph.neighbors(current_node))\n",
    "    weights = []\n",
    "    for neighbor in neighbors:\n",
    "        if neighbor == prev_node:\n",
    "            weights.append(1/p)\n",
    "        elif graph.has_edge(prev_node, neighbor):\n",
    "            weights.append(1)\n",
    "        else:\n",
    "            weights.append(1/q)\n",
    "    return random.choices(neighbors, weights=weights)[0]\n",
    "\n",
    "def gen_biaised_random_walk_tensor(graph, start_node, walk_length, num_walks, p, q , neighbors_dict):\n",
    "    walks = torch.zeros((num_walks, walk_length), dtype=int)\n",
    "    walks[:, 0] = start_node\n",
    "\n",
    "    for walk_index in range(num_walks):\n",
    "        current_node = start_node\n",
    "        for step in range(walk_length):\n",
    "            walks[walk_index, step] = current_node\n",
    "            if step > 0:\n",
    "                prev_node = int(walks[walk_index, step - 1])\n",
    "                current_node = get_next_node(graph,prev_node,current_node,p,q)\n",
    "            else:\n",
    "                current_node = np.random.choice(list(graph.neighbors(current_node)))\n",
    "            \n",
    "    \n",
    "    return walks\n",
    "\n",
    "def get_next_node(graph,t,v, p, q):\n",
    "    v_neighbors = set(graph.neighbors(v))\n",
    "    t_neighbors = set(graph.neighbors(t))\n",
    "    t_set = set([t])\n",
    "\n",
    "    vt_neighbors = v_neighbors & t_neighbors\n",
    "    only_v_neighbors = v_neighbors - t_neighbors - t_set\n",
    "\n",
    "    allsets = [vt_neighbors,only_v_neighbors,t_set]\n",
    "\n",
    "    vt_weights = 1 * len(vt_neighbors)\n",
    "    only_v_weights = 1/q * len(only_v_neighbors)\n",
    "    t_weight = 1/p\n",
    "\n",
    "    prob_vector = np.array((vt_weights,only_v_weights,t_weight))\n",
    "    prob_vector = prob_vector / np.sum(prob_vector)\n",
    "\n",
    "    chosen_set = np.random.choice(allsets,p=prob_vector)\n",
    "    next_node = np.random.choice(list(chosen_set))\n",
    "    return next_node\n",
    "\n",
    "# Assert all edges exist\n",
    "graph = bc_dataset['graph']\n",
    "neighbors_dict = {node: list(graph.neighbors(node)) for node in graph.nodes}\n",
    "rws = gen_biaised_random_walk_tensor(bc_dataset['graph'], 1, 5, 3, 0.00001, 5, neighbors_dict)\n",
    "rws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3e89a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_node(graph,t,v, p, q):\n",
    "    v_neighbors = set(graph.neighbors(v))\n",
    "    t_neighbors = set(graph.neighbors(t))\n",
    "    t_set = set([t])\n",
    "\n",
    "    vt_neighbors = v_neighbors & t_neighbors\n",
    "    only_v_neighbors = v_neighbors - t_neighbors - t_set\n",
    "\n",
    "    allsets = [vt_neighbors,only_v_neighbors,t_set]\n",
    "\n",
    "    vt_weights = 1 * len(vt_neighbors)\n",
    "    only_v_weights = 1/q * len(only_v_neighbors)\n",
    "    t_weight = 1/p\n",
    "\n",
    "    prob_vector = np.array((vt_weights,only_v_weights,t_weight))\n",
    "    prob_vector = prob_vector / np.sum(prob_vector)\n",
    "\n",
    "    chosen_set = np.random.choice(allsets,p=prob_vector)\n",
    "    next_node = np.random.choice(list(chosen_set))\n",
    "    return next_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e24c28d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch_biaised_random_walk(graph, initial_nodes, length, num_walks, p, q, neighbors_dict):\n",
    "    n_nodes = initial_nodes.shape[0]\n",
    "    walk = torch.zeros((num_walks*n_nodes, length), dtype=int)\n",
    "    for i, n in enumerate(initial_nodes):\n",
    "        n = n.item()\n",
    "        walk[num_walks*i:num_walks*(i+1)] = gen_biaised_random_walk_tensor(graph, n, length, num_walks, p, q,neighbors_dict)\n",
    "    return walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "343314b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   21,   73,    6,  353],\n",
       "        [   0,   61,    8, 7303, 6071],\n",
       "        [   0,   94,  103,  580,   94],\n",
       "        [   1, 2628, 2048, 5846,  194],\n",
       "        [   1, 4853, 1049,  913, 3200],\n",
       "        [   1, 1190, 4655, 2106,  387]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw = gen_batch_biaised_random_walk(bc_dataset['graph'], torch.tensor([0, 1]), 5, 3, 5, 5, neighbors_dict)\n",
    "rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57636b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   21,   73],\n",
       "        [   0,   61,    8],\n",
       "        [   0,   94,  103],\n",
       "        [   1, 2628, 2048],\n",
       "        [   1, 4853, 1049],\n",
       "        [   1, 1190, 4655],\n",
       "        [  21,   73,    6],\n",
       "        [  61,    8, 7303],\n",
       "        [  94,  103,  580],\n",
       "        [2628, 2048, 5846],\n",
       "        [4853, 1049,  913],\n",
       "        [1190, 4655, 2106],\n",
       "        [  73,    6,  353],\n",
       "        [   8, 7303, 6071],\n",
       "        [ 103,  580,   94],\n",
       "        [2048, 5846,  194],\n",
       "        [1049,  913, 3200],\n",
       "        [4655, 2106,  387]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_windows(random_walk, window_size):\n",
    "    num_walks, walk_length = random_walk.shape\n",
    "    # number of windows: e.g. length 5, window size 3 -> 3 windows ([0, 1, 2], [1, 2, 3], [2, 3, 4])\n",
    "    num_windows = walk_length + 1 - window_size\n",
    "    windows = torch.zeros((num_walks*num_windows, window_size), dtype=int)\n",
    "    for j in range(num_windows):\n",
    "        windows[num_walks*j:num_walks*(j+1)] = random_walk[:, j:j+window_size]\n",
    "    return windows\n",
    "\n",
    "windows = generate_windows(rw, 3)\n",
    "windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b455fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.0514, -11.8062],\n",
       "        [-23.1137,  12.3963],\n",
       "        [ -8.5642, -12.9514],\n",
       "        [ 14.8714,  -1.1188],\n",
       "        [-17.5598,  25.6971],\n",
       "        [  6.8539,  -1.2695],\n",
       "        [ 15.9283,  11.3855],\n",
       "        [ -2.8707,  -2.2326],\n",
       "        [  6.3725,  11.7856],\n",
       "        [  5.6913,  -2.5457],\n",
       "        [ 10.0821, -18.3061],\n",
       "        [ -9.1678,  13.1134],\n",
       "        [-10.1190,  18.3956],\n",
       "        [ 14.6302, -26.6076],\n",
       "        [ 20.6556,   6.3725],\n",
       "        [-15.6468,  -8.2554],\n",
       "        [-17.9830,   0.9629],\n",
       "        [ -0.7161, -21.9275]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_windows_dotproduct(windows, embedding):\n",
    "    embedding_size = embedding.shape[1]\n",
    "    # get the embedding of the initial node repeated num_windows times\n",
    "    first_emb = embedding[windows[:, 0]]\n",
    "    first_emb = first_emb.view(windows.shape[0], 1, embedding_size)\n",
    "    # get the embedding of the remaining nodes in each window\n",
    "    others_emb = embedding[windows[:, 1:]]\n",
    "    others_emb = others_emb.view(windows.shape[0], -1, embedding_size)\n",
    "    # result has same shape as others\n",
    "    # Each element is the dot product between the corresponding node embedding\n",
    "    # and the embedding of the first node of that walk\n",
    "    # that is, result_{i, j} for random walk i and element j is v_{W_{i, 0}} dot v_{W_{i, j}}\n",
    "    result = (first_emb*others_emb).sum(dim=-1)\n",
    "    return result\n",
    "\n",
    "embedding = torch.randn((12000, 300))\n",
    "get_windows_dotproduct(windows, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "69c57727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.9715)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(torch.sigmoid(get_windows_dotproduct(windows, embedding))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f8b31f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,  982,  615, 1384, 1993],\n",
       "        [   0,  291, 1565,  631,  585],\n",
       "        [   0, 1023, 1619,   58, 1803]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_negative_samples(amount, length, initial_node, number_of_nodes):\n",
    "    negative_samples = torch.zeros((amount, length), dtype=int)\n",
    "    negative_samples[:, 0] = initial_node\n",
    "    negative_samples[:, 1:] = torch.randint(number_of_nodes, (amount, length-1))\n",
    "    return negative_samples\n",
    "\n",
    "gen_negative_samples(amount=3, length=5, initial_node=0, number_of_nodes=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e11f6857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 1119,  931, 1109,  718],\n",
       "        [   0,  182, 1496,  249,  559],\n",
       "        [   0,  842,  808,  482,   21],\n",
       "        [   1, 1784, 1770, 1948,  941],\n",
       "        [   1, 1000, 1723,  578,  828],\n",
       "        [   1,  273, 1926, 1323, 1527]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_batch_negative_samples(amount, length, initial_nodes, number_of_nodes):\n",
    "    negative_samples = torch.zeros((amount*initial_nodes.shape[0], length), dtype=int)\n",
    "    negative_samples[:, 0] = initial_nodes.repeat(amount, 1).t().contiguous().view(-1)\n",
    "    negative_samples[:, 1:] = torch.randint(number_of_nodes, (amount*initial_nodes.shape[0], length-1))\n",
    "    return negative_samples\n",
    "\n",
    "gen_batch_negative_samples(amount=3, length=5, initial_nodes=torch.tensor([0, 1]), number_of_nodes=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "21b70a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "[40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
      "[60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "[100]\n"
     ]
    }
   ],
   "source": [
    "def generate_batches(array, batch_size):\n",
    "    \"\"\"Yield successive batches of size `batch_size` from `array`.\"\"\"\n",
    "    for i in range(0, len(array), batch_size):\n",
    "        yield array[i:i + batch_size]\n",
    "\n",
    "gen = generate_batches(list(range(101)), 20)\n",
    "for batch in gen:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2ed30782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "eps = 1e-15\n",
    "\n",
    "def deepWalk(graph, walks_per_vertex, walk_length, window_size, embedding_size, num_neg, lr, epochs, batch_size, p = 5, q = 5):\n",
    "    number_of_nodes = graph.number_of_nodes()\n",
    "    \n",
    "    embedding = (torch.randn(size=(number_of_nodes, embedding_size)) ).detach()\n",
    "    embedding.requires_grad = True\n",
    "    optimizer = torch.optim.Adam([embedding], lr=lr)\n",
    "    loss_history = {'pos': [], 'neg': [], 'total': []}\n",
    "    neighbors_dict = {node: list(graph.neighbors(node)) for node in graph.nodes}\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        nodes = torch.tensor(list(graph.nodes), dtype=int)\n",
    "        random.shuffle(nodes)\n",
    "        node_loader = generate_batches(nodes, batch_size)\n",
    "        n_batches = int(number_of_nodes / batch_size)\n",
    "        for n in tqdm(node_loader, total=n_batches):\n",
    "            random_walk = gen_batch_biaised_random_walk(graph, n, walk_length, walks_per_vertex, p, q, neighbors_dict)\n",
    "            num_windows = walk_length + 1 - window_size\n",
    "\n",
    "            # Positive Sampling\n",
    "            # each row of windows is one window, we have B = walks_per_vertex*num_windows windows\n",
    "            windows = generate_windows(random_walk, window_size)\n",
    "            batch_dotproduct = get_windows_dotproduct(windows, embedding)\n",
    "            # takes the sigmoid of the dot product to get probability, then\n",
    "            # takes the loglik and average through all elements\n",
    "            pos_loss = -torch.log(torch.sigmoid(batch_dotproduct)+eps).mean()\n",
    "            # Negative Sampling\n",
    "            negative_samples = gen_batch_negative_samples(\n",
    "                amount=num_neg*walks_per_vertex, \n",
    "                length=walk_length, \n",
    "                initial_nodes=n, \n",
    "                number_of_nodes=number_of_nodes\n",
    "            )\n",
    "            windows = generate_windows(negative_samples, window_size)\n",
    "            batch_dotproduct = get_windows_dotproduct(windows, embedding)\n",
    "            neg_loss = -torch.log(1-torch.sigmoid(batch_dotproduct)+eps).mean()\n",
    "\n",
    "            loss = pos_loss + neg_loss\n",
    "            # Optimization\n",
    "            loss.backward()\n",
    "            loss_history['total'].append(loss.detach().numpy())\n",
    "            loss_history['pos'].append(pos_loss.detach().numpy())\n",
    "            loss_history['neg'].append(neg_loss.detach().numpy())\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    return embedding, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "38f0c9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/206 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 47/206 [02:22<08:02,  3.03s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m embedding, loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mdeepWalk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbc_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgraph\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mwalks_per_vertex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwalk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43membedding_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_neg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[74], line 19\u001b[0m, in \u001b[0;36mdeepWalk\u001b[1;34m(graph, walks_per_vertex, walk_length, window_size, embedding_size, num_neg, lr, epochs, batch_size, p, q)\u001b[0m\n\u001b[0;32m     17\u001b[0m n_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(number_of_nodes \u001b[38;5;241m/\u001b[39m batch_size)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m tqdm(node_loader, total\u001b[38;5;241m=\u001b[39mn_batches):\n\u001b[1;32m---> 19\u001b[0m     random_walk \u001b[38;5;241m=\u001b[39m \u001b[43mgen_batch_biaised_random_walk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwalk_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwalks_per_vertex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbors_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     num_windows \u001b[38;5;241m=\u001b[39m walk_length \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m window_size\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Positive Sampling\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# each row of windows is one window, we have B = walks_per_vertex*num_windows windows\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[66], line 6\u001b[0m, in \u001b[0;36mgen_batch_biaised_random_walk\u001b[1;34m(graph, initial_nodes, length, num_walks, p, q, neighbors_dict)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(initial_nodes):\n\u001b[0;32m      5\u001b[0m     n \u001b[38;5;241m=\u001b[39m n\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m----> 6\u001b[0m     walk[num_walks\u001b[38;5;241m*\u001b[39mi:num_walks\u001b[38;5;241m*\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m \u001b[43mgen_biaised_random_walk_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_walks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43mneighbors_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m walk\n",
      "Cell \u001b[1;32mIn[64], line 45\u001b[0m, in \u001b[0;36mgen_biaised_random_walk_tensor\u001b[1;34m(graph, start_node, walk_length, num_walks, p, q, neighbors_dict)\u001b[0m\n\u001b[0;32m     43\u001b[0m walks[walk_index, step] \u001b[38;5;241m=\u001b[39m current_node\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 45\u001b[0m     prev_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwalks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mwalk_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     current_node \u001b[38;5;241m=\u001b[39m get_next_node(graph,prev_node,current_node,p,q)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding, loss_history = deepWalk(graph=bc_dataset['graph'],  walks_per_vertex=5, walk_length=40, window_size=10,  embedding_size=128,num_neg=5,lr=1e-2,epochs=10,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b2bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cumsum_vec = np.cumsum(np.insert(loss_history['total'], 0, 0)) \n",
    "print(cumsum_vec.shape)\n",
    "window_width = 10\n",
    "ma_vec = (cumsum_vec[window_width:] - cumsum_vec[:-window_width]) / window_width\n",
    "plt.plot(ma_vec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2255e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arthu\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1287820015515904"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = embedding.detach().numpy()\n",
    "y = bc_dataset['labels']\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "y_hat = clf.predict(X)\n",
    "f1_score(y, y_hat, average='micro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
