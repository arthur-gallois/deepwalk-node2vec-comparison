{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10b307a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pickle as p\n",
    "from os import path\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "\n",
    "data_loc = 'C:/Users/alex_/Fac/M2/M2/S2/Discrete_Graphs/Projet/Data/BlogCatalog3/BlogCatalog-dataset/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba68a41f",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07063a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:  10312\n",
      "Number of edges:  333983\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    iid = {}\n",
    "    idx = 0\n",
    "    edgelist = []\n",
    "\n",
    "    # Read edges pairs\n",
    "    with open(data_loc+'edges.csv', 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            i, j = line.strip().split(',')  # csv\n",
    "            if i not in iid:\n",
    "                iid[i] = idx; idx += 1\n",
    "            if j not in iid:\n",
    "                iid[j] = idx; idx += 1\n",
    "            edgelist.append((iid[i], iid[j]))\n",
    "\n",
    "    # Create an nx undirected network\n",
    "    bc = nx.Graph(edgelist)\n",
    "\n",
    "    print(\"Number of nodes: \", len(bc))\n",
    "    print(\"Number of edges: \", bc.size())\n",
    "\n",
    "    # Read labels\n",
    "    labels = np.zeros((len(bc)), dtype=int)\n",
    "    # Read (node_id, label) file\n",
    "    with open(data_loc+'group-edges.csv', 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            node, group = line.strip().split(',') \n",
    "            labels[iid[node]] = int(group)-1  \n",
    "\n",
    "    bc_dataset = {'graph': bc, 'labels': labels}\n",
    "    return bc_dataset\n",
    "\n",
    "bc_dataset = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e5baaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "38\n",
      "[[   0   60]\n",
      " [   1  488]\n",
      " [   2  365]\n",
      " [   3  119]\n",
      " [   4  625]\n",
      " [   5  563]\n",
      " [   6  393]\n",
      " [   7 1076]\n",
      " [   8  247]\n",
      " [   9  300]\n",
      " [  10  325]\n",
      " [  11   25]\n",
      " [  12   35]\n",
      " [  13  239]\n",
      " [  14   53]\n",
      " [  15  295]\n",
      " [  16  351]\n",
      " [  17  236]\n",
      " [  18  715]\n",
      " [  19  247]\n",
      " [  20  228]\n",
      " [  21  233]\n",
      " [  22  279]\n",
      " [  23  846]\n",
      " [  24  170]\n",
      " [  25  242]\n",
      " [  26   88]\n",
      " [  27   85]\n",
      " [  28  155]\n",
      " [  29  360]\n",
      " [  30   62]\n",
      " [  31  371]\n",
      " [  32   91]\n",
      " [  33   62]\n",
      " [  34   58]\n",
      " [  35  137]\n",
      " [  36   53]\n",
      " [  37   27]\n",
      " [  38    8]]\n"
     ]
    }
   ],
   "source": [
    "print(np.min(bc_dataset['labels']))\n",
    "print(np.max(bc_dataset['labels']))\n",
    "unique, counts = np.unique(bc_dataset['labels'], return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82ae8b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   55,  952, 7023,  185],\n",
       "        [   0,  103, 8440,   50, 4226],\n",
       "        [   0,   69, 3101,   37, 1572]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def gen_biaised_random_walk_tensor(graph, start_node, walk_length, num_walks, p, q):\n",
    "    walk = torch.zeros((num_walks, walk_length), dtype=int)\n",
    "    walk[:, 0] = start_node\n",
    "    j = 0\n",
    "    while j < num_walks:\n",
    "        current_node = start_node\n",
    "        step = 1\n",
    "        while step < walk_length:\n",
    "            neighbors = list(graph.neighbors(current_node))\n",
    "            if step == 1:\n",
    "                current_node = random.choice(neighbors)\n",
    "            else:\n",
    "                prev_node = walk[j,step-1]\n",
    "                current_node = biased_choose_next_node(graph, current_node, prev_node, p, q)\n",
    "            walk[j, step] = current_node\n",
    "            step += 1\n",
    "        j+=1\n",
    "    return walk\n",
    "\n",
    "\n",
    "def biased_choose_next_node(graph, current_node, prev_node, p, q):\n",
    "    neighbors = list(graph.neighbors(current_node))\n",
    "    weights = []\n",
    "    for neighbor in neighbors:\n",
    "        if neighbor == prev_node:\n",
    "            weights.append(1/p)\n",
    "        elif graph.has_edge(prev_node, neighbor):\n",
    "            weights.append(1)\n",
    "        else:\n",
    "            weights.append(1/q)\n",
    "    return random.choices(neighbors, weights=weights)[0]\n",
    "\n",
    "def gen_biaised_random_walk_tensor(graph, start_node, walk_length, num_walks, p, q , neighbors_dict):\n",
    "    walks = torch.zeros((num_walks, walk_length), dtype=int)\n",
    "    walks[:, 0] = start_node\n",
    "\n",
    "    for walk_index in range(num_walks):\n",
    "        current_node = start_node\n",
    "        for step in range(walk_length):\n",
    "            walks[walk_index, step] = current_node\n",
    "            neighbors = neighbors_dict[current_node]\n",
    "            if step > 0:\n",
    "                prev_node = walks[walk_index, step - 1]\n",
    "            else:\n",
    "                prev_node = None\n",
    "            current_node = biased_choose_next_node(neighbors, prev_node, p, q, graph)\n",
    "    \n",
    "    return walks\n",
    "\n",
    "def biased_choose_next_node(neighbors, prev_node, p, q, graph):\n",
    "    weights = []\n",
    "    for neighbor in neighbors:\n",
    "        if neighbor == prev_node:\n",
    "            weights.append(1/p)\n",
    "        elif graph.has_edge(prev_node, neighbor):\n",
    "            weights.append(1)\n",
    "        else:\n",
    "            weights.append(1/q)\n",
    "    return random.choices(neighbors, weights=weights)[0]\n",
    "\n",
    "# Assert all edges exist\n",
    "graph = bc_dataset['graph']\n",
    "neighbors_dict = {node: list(graph.neighbors(node)) for node in graph.nodes}\n",
    "rws = gen_biaised_random_walk_tensor(bc_dataset['graph'], 0, 5, 3, 5, 5, neighbors_dict)\n",
    "rws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec1754be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         22819 function calls in 0.026 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       15    0.020    0.001    0.026    0.002 476093457.py:53(biased_choose_next_node)\n",
      "     5849    0.003    0.000    0.005    0.000 graph.py:1274(has_edge)\n",
      "     5492    0.001    0.000    0.001    0.000 _tensor.py:1002(__hash__)\n",
      "        1    0.001    0.001    0.026    0.026 476093457.py:36(gen_biaised_random_walk_tensor)\n",
      "     5861    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "     5492    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "       15    0.000    0.000    0.000    0.000 random.py:480(choices)\n",
      "        1    0.000    0.000    0.026    0.026 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.zeros}\n",
      "       15    0.000    0.000    0.000    0.000 random.py:514(<listcomp>)\n",
      "       15    0.000    0.000    0.000    0.000 {built-in method _bisect.bisect_right}\n",
      "       30    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.026    0.026 <string>:1(<module>)\n",
      "       15    0.000    0.000    0.000    0.000 {method 'random' of '_random.Random' objects}\n",
      "       15    0.000    0.000    0.000    0.000 {built-in method math.isfinite}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}"
     ]
    }
   ],
   "source": [
    "%prun gen_biaised_random_walk_tensor(bc_dataset['graph'], 0, 5, 3, 5, 5, neighbors_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e24c28d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch_biaised_random_walk(graph, initial_nodes, length, num_walks, p, q, neighbors_dict):\n",
    "    n_nodes = initial_nodes.shape[0]\n",
    "    walk = torch.zeros((num_walks*n_nodes, length), dtype=int)\n",
    "    for i, n in enumerate(initial_nodes):\n",
    "        n = n.item()\n",
    "        walk[num_walks*i:num_walks*(i+1)] = gen_biaised_random_walk_tensor(graph, n, length, num_walks, p, q,neighbors_dict)\n",
    "    return walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "343314b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   67, 1234,   62, 4458],\n",
       "        [   0,   39, 5494,   50, 9267],\n",
       "        [   0,   69, 2856,  880, 1598],\n",
       "        [   1,  501, 1269, 1283,  206],\n",
       "        [   1, 4285,  116, 4653,  116],\n",
       "        [   1,  207,   33, 6557, 3482]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw = gen_batch_biaised_random_walk(bc_dataset['graph'], torch.tensor([0, 1]), 5, 3, 5, 5, neighbors_dict)\n",
    "rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57636b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,   67, 1234],\n",
       "        [   0,   39, 5494],\n",
       "        [   0,   69, 2856],\n",
       "        [   1,  501, 1269],\n",
       "        [   1, 4285,  116],\n",
       "        [   1,  207,   33],\n",
       "        [  67, 1234,   62],\n",
       "        [  39, 5494,   50],\n",
       "        [  69, 2856,  880],\n",
       "        [ 501, 1269, 1283],\n",
       "        [4285,  116, 4653],\n",
       "        [ 207,   33, 6557],\n",
       "        [1234,   62, 4458],\n",
       "        [5494,   50, 9267],\n",
       "        [2856,  880, 1598],\n",
       "        [1269, 1283,  206],\n",
       "        [ 116, 4653,  116],\n",
       "        [  33, 6557, 3482]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_windows(random_walk, window_size):\n",
    "    num_walks, walk_length = random_walk.shape\n",
    "    # number of windows: e.g. length 5, window size 3 -> 3 windows ([0, 1, 2], [1, 2, 3], [2, 3, 4])\n",
    "    num_windows = walk_length + 1 - window_size\n",
    "    windows = torch.zeros((num_walks*num_windows, window_size), dtype=int)\n",
    "    for j in range(num_windows):\n",
    "        windows[num_walks*j:num_walks*(j+1)] = random_walk[:, j:j+window_size]\n",
    "    return windows\n",
    "\n",
    "windows = generate_windows(rw, 3)\n",
    "windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b455fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.4526,  -8.5567],\n",
       "        [-25.0469, -25.4825],\n",
       "        [-17.8251,  -9.9009],\n",
       "        [  5.9120,  -7.1553],\n",
       "        [-24.1592,  -4.2591],\n",
       "        [ 11.9589,  14.0415],\n",
       "        [  9.0637,  -9.1147],\n",
       "        [  1.3122, -11.5282],\n",
       "        [ -0.3533, -22.0148],\n",
       "        [ -7.1154,   4.5086],\n",
       "        [-20.2794,  15.1952],\n",
       "        [  5.6194,  -2.3813],\n",
       "        [ 30.9110,   6.6523],\n",
       "        [ -6.4609,   2.7763],\n",
       "        [ 14.2588,  -5.1666],\n",
       "        [ 22.5989,  10.9150],\n",
       "        [-15.3165, 287.0930],\n",
       "        [-24.6010,   6.0363]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_windows_dotproduct(windows, embedding):\n",
    "    embedding_size = embedding.shape[1]\n",
    "    # get the embedding of the initial node repeated num_windows times\n",
    "    first_emb = embedding[windows[:, 0]]\n",
    "    first_emb = first_emb.view(windows.shape[0], 1, embedding_size)\n",
    "    # get the embedding of the remaining nodes in each window\n",
    "    others_emb = embedding[windows[:, 1:]]\n",
    "    others_emb = others_emb.view(windows.shape[0], -1, embedding_size)\n",
    "    # result has same shape as others\n",
    "    # Each element is the dot product between the corresponding node embedding\n",
    "    # and the embedding of the first node of that walk\n",
    "    # that is, result_{i, j} for random walk i and element j is v_{W_{i, 0}} dot v_{W_{i, j}}\n",
    "    result = (first_emb*others_emb).sum(dim=-1)\n",
    "    return result\n",
    "\n",
    "embedding = torch.randn((12000, 300))\n",
    "get_windows_dotproduct(windows, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69c57727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6.8859)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(torch.sigmoid(get_windows_dotproduct(windows, embedding))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8b31f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,  250, 1938, 1871,  505],\n",
       "        [   0, 1590,  435,  176, 1048],\n",
       "        [   0, 1843, 1017, 1680, 1134]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_negative_samples(amount, length, initial_node, number_of_nodes):\n",
    "    negative_samples = torch.zeros((amount, length), dtype=int)\n",
    "    negative_samples[:, 0] = initial_node\n",
    "    negative_samples[:, 1:] = torch.randint(number_of_nodes, (amount, length-1))\n",
    "    return negative_samples\n",
    "\n",
    "gen_negative_samples(amount=3, length=5, initial_node=0, number_of_nodes=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e11f6857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 1818, 1964,  862,  178],\n",
       "        [   0, 1608, 1036,  638,  782],\n",
       "        [   0,  189,  175, 1469, 1759],\n",
       "        [   1, 1225,  945, 1562, 1394],\n",
       "        [   1,  320,  468,  114, 1382],\n",
       "        [   1, 1636, 1699,  138, 1503]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_batch_negative_samples(amount, length, initial_nodes, number_of_nodes):\n",
    "    negative_samples = torch.zeros((amount*initial_nodes.shape[0], length), dtype=int)\n",
    "    negative_samples[:, 0] = initial_nodes.repeat(amount, 1).t().contiguous().view(-1)\n",
    "    negative_samples[:, 1:] = torch.randint(number_of_nodes, (amount*initial_nodes.shape[0], length-1))\n",
    "    return negative_samples\n",
    "\n",
    "gen_batch_negative_samples(amount=3, length=5, initial_nodes=torch.tensor([0, 1]), number_of_nodes=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21b70a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "[40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
      "[60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "[100]\n"
     ]
    }
   ],
   "source": [
    "def generate_batches(array, batch_size):\n",
    "    \"\"\"Yield successive batches of size `batch_size` from `array`.\"\"\"\n",
    "    for i in range(0, len(array), batch_size):\n",
    "        yield array[i:i + batch_size]\n",
    "\n",
    "gen = generate_batches(list(range(101)), 20)\n",
    "for batch in gen:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ed30782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "eps = 1e-15\n",
    "\n",
    "def deepWalk(graph, walks_per_vertex, walk_length, window_size, embedding_size, num_neg, lr, epochs, batch_size, p = 5, q = 5):\n",
    "    number_of_nodes = graph.number_of_nodes()\n",
    "    \n",
    "    embedding = (torch.randn(size=(number_of_nodes, embedding_size)) ).detach()\n",
    "    embedding.requires_grad = True\n",
    "    optimizer = torch.optim.Adam([embedding], lr=lr)\n",
    "    loss_history = {'pos': [], 'neg': [], 'total': []}\n",
    "    neighbors_dict = {node: list(graph.neighbors(node)) for node in graph.nodes}\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        nodes = torch.tensor(list(graph.nodes), dtype=int)\n",
    "        random.shuffle(nodes)\n",
    "        node_loader = generate_batches(nodes, batch_size)\n",
    "        n_batches = int(number_of_nodes / batch_size)\n",
    "        for n in tqdm(node_loader, total=n_batches):\n",
    "            random_walk = gen_batch_biaised_random_walk(graph, n, walk_length, walks_per_vertex, p, q, neighbors_dict)\n",
    "            num_windows = walk_length + 1 - window_size\n",
    "\n",
    "            # Positive Sampling\n",
    "            # each row of windows is one window, we have B = walks_per_vertex*num_windows windows\n",
    "            windows = generate_windows(random_walk, window_size)\n",
    "            batch_dotproduct = get_windows_dotproduct(windows, embedding)\n",
    "            # takes the sigmoid of the dot product to get probability, then\n",
    "            # takes the loglik and average through all elements\n",
    "            pos_loss = -torch.log(torch.sigmoid(batch_dotproduct)+eps).mean()\n",
    "            # Negative Sampling\n",
    "            negative_samples = gen_batch_negative_samples(\n",
    "                amount=num_neg*walks_per_vertex, \n",
    "                length=walk_length, \n",
    "                initial_nodes=n, \n",
    "                number_of_nodes=number_of_nodes\n",
    "            )\n",
    "            windows = generate_windows(negative_samples, window_size)\n",
    "            batch_dotproduct = get_windows_dotproduct(windows, embedding)\n",
    "            neg_loss = -torch.log(1-torch.sigmoid(batch_dotproduct)+eps).mean()\n",
    "\n",
    "            loss = pos_loss + neg_loss\n",
    "            # Optimization\n",
    "            loss.backward()\n",
    "            loss_history['total'].append(loss.detach().numpy())\n",
    "            loss_history['pos'].append(pos_loss.detach().numpy())\n",
    "            loss_history['neg'].append(neg_loss.detach().numpy())\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()  \n",
    "\n",
    "    return embedding, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "38f0c9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/206 [00:24<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         21828400 function calls in 24.726 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    10000   18.819    0.002   24.134    0.002 476093457.py:53(biased_choose_next_node)\n",
      "  5552898    3.309    0.000    4.686    0.000 graph.py:1274(has_edge)\n",
      "  5287657    0.986    0.000    1.377    0.000 _tensor.py:1002(__hash__)\n",
      "  5287659    0.391    0.000    0.391    0.000 {built-in method builtins.id}\n",
      "  5562658    0.385    0.000    0.385    0.000 {method 'append' of 'list' objects}\n",
      "       50    0.231    0.005   24.366    0.487 476093457.py:36(gen_biaised_random_walk_tensor)\n",
      "    10000    0.219    0.000    0.243    0.000 random.py:480(choices)\n",
      "        1    0.142    0.142    0.142    0.142 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
      "        1    0.074    0.074    0.081    0.081 random.py:376(shuffle)\n",
      "        2    0.074    0.037    0.085    0.042 3143600304.py:1(get_windows_dotproduct)\n",
      "        1    0.016    0.016    0.019    0.019 2511371920.py:11(<dictcomp>)\n",
      "    10000    0.011    0.000    0.019    0.000 random.py:514(<listcomp>)\n",
      "        2    0.010    0.005    0.010    0.005 {method 'sum' of 'torch._C._TensorBase' objects}\n",
      "        1    0.006    0.006    0.006    0.006 {built-in method torch.randn}\n",
      "    10000    0.006    0.000    0.006    0.000 {built-in method _bisect.bisect_right}\n",
      "    10311    0.005    0.000    0.006    0.000 random.py:235(_randbelow_with_getrandbits)\n",
      "    20016    0.003    0.000    0.003    0.000 {built-in method builtins.len}\n",
      "    10312    0.003    0.000    0.003    0.000 graph.py:1315(neighbors)\n",
      "    10000    0.003    0.000    0.003    0.000 {method 'random' of '_random.Random' objects}\n",
      "       54    0.003    0.000    0.003    0.000 {built-in method torch.zeros}\n",
      "        1    0.002    0.002   24.726   24.726 <string>:1(<module>)\n",
      "    10000    0.002    0.000    0.002    0.000 {built-in method math.isfinite}\n",
      "        1    0.002    0.002    0.002    0.002 {method 'unbind' of 'torch._C._TensorBase' objects}\n",
      "        1    0.002    0.002    0.006    0.006 adam.py:330(_single_tensor_adam)\n",
      "        2    0.002    0.001    0.002    0.001 {built-in method torch.sigmoid}\n",
      "       31    0.002    0.000    0.002    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        1    0.002    0.002   24.724   24.724 2511371920.py:4(deepWalk)\n",
      "        1    0.001    0.001    0.001    0.001 {method 'lerp_' of 'torch._C._TensorBase' objects}\n",
      "        1    0.001    0.001   24.369   24.369 2239623765.py:1(gen_batch_biaised_random_walk)\n",
      "       11    0.001    0.000    0.001    0.000 socket.py:613(send)\n",
      "        2    0.001    0.001    0.001    0.001 {built-in method torch.log}\n",
      "    15121    0.001    0.000    0.001    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
      "        2    0.001    0.001    0.002    0.001 2214940036.py:1(generate_windows)\n",
      "        2    0.001    0.000    0.001    0.000 {method 'mean' of 'torch._C._TensorBase' objects}\n",
      "        1    0.001    0.001    0.001    0.001 {method 'sqrt' of 'torch._C._TensorBase' objects}\n",
      "        1    0.001    0.001    0.001    0.001 {method 'addcdiv_' of 'torch._C._TensorBase' objects}\n",
      "        2    0.001    0.000    0.001    0.000 {built-in method torch.zeros_like}\n",
      "    10315    0.001    0.000    0.001    0.000 {built-in method builtins.iter}\n",
      "        2    0.001    0.000    0.001    0.000 {built-in method torch.tensor}\n",
      "        1    0.001    0.001    0.001    0.001 {built-in method torch.rsub}\n",
      "    10311    0.001    0.000    0.001    0.000 {method 'bit_length' of 'int' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'addcmul_' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.001    0.001 508423023.py:1(gen_batch_negative_samples)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method nt.stat}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.randint}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'add_' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}\n",
      "       51    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._ops.profiler._record_function_enter_new}\n",
      "        1    0.000    0.000   24.726   24.726 {built-in method builtins.exec}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "        1    0.000    0.000    0.007    0.007 optimizer.py:356(wrapper)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:352(format_meter)\n",
      "        2    0.000    0.000    0.001    0.000 eval_frame.py:267(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._ops.profiler.}\n",
      "        4    0.000    0.000    0.002    0.000 threading.py:604(wait)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:236(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'repeat' of 'torch._C._TensorBase' objects}\n",
      "        4    0.000    0.000    0.001    0.000 iostream.py:534(write)\n",
      "       11    0.000    0.000    0.001    0.000 iostream.py:203(schedule)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:228(_screen_shape_windows)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:48(create_string_buffer)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:846(add_param_group)\n",
      "        4    0.000    0.000    0.002    0.001 iostream.py:479(flush)\n",
      "        1    0.000    0.000    0.002    0.002 std.py:837(__init__)\n",
      "        1    0.000    0.000    0.001    0.001 adam.py:80(_init_group)\n",
      "        2    0.000    0.000    0.000    0.000 1336715503.py:1(generate_batches)\n",
      "        1    0.000    0.000    0.007    0.007 optimizer.py:58(_use_grad)\n",
      "        2    0.000    0.000    0.000    0.000 profiler.py:636(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 _tensor.py:964(__len__)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'detach' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:936(getsourcefile)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "        2    0.000    0.000    0.002    0.001 std.py:1262(close)\n",
      "        4    0.000    0.000    0.002    0.000 threading.py:288(wait)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'numpy' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.142    0.142 __init__.py:149(backward)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:776(zero_grad)\n",
      "        6    0.000    0.000    0.002    0.000 utils.py:125(inner)\n",
      "       80    0.000    0.000    0.000    0.000 utils.py:306(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 eval_frame.py:307(_fn)\n",
      "        5    0.000    0.000    0.000    0.000 std.py:101(acquire)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.006    0.006 adam.py:254(adam)\n",
      "        1    0.000    0.000    0.007    0.007 adam.py:130(step)\n",
      "        2    0.000    0.000    0.000    0.000 optimizer.py:122(<genexpr>)\n",
      "       15    0.000    0.000    0.000    0.000 threading.py:1185(is_alive)\n",
      "        2    0.000    0.000    0.001    0.000 _compile.py:20(inner)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:109(_default_to_fused_or_foreach)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:56(_make_grads)\n",
      "        2    0.000    0.000    0.002    0.001 std.py:1157(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:551(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x00007FFF8C28A4B0}\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:239(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'contiguous' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.001    0.000 decorators.py:33(disable)\n",
      "       30    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        2    0.000    0.000    0.000    0.000 profiler.py:619(__init__)\n",
      "        1    0.000    0.000    0.142    0.142 _tensor.py:433(backward)\n",
      "        1    0.000    0.000    0.001    0.001 std.py:326(status_printer)\n",
      "        5    0.000    0.000    0.000    0.000 std.py:105(release)\n",
      "        4    0.000    0.000    0.000    0.000 utils.py:204(_is_ascii)\n",
      "        2    0.000    0.000    0.000    0.000 functools.py:35(update_wrapper)\n",
      "       11    0.000    0.000    0.000    0.000 iostream.py:90(_event_pipe)\n",
      "        2    0.000    0.000    0.000    0.000 profiler.py:630(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.ones_like}\n",
      "        1    0.000    0.000    0.000    0.000 std.py:574(_decr_instances)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method torch._C._get_tracing_state}\n",
      "       46    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.000    0.000 {method 't' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.001    0.001 _tensor.py:34(wrapped)\n",
      "        2    0.000    0.000    0.002    0.001 std.py:1461(display)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1147(__str__)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:896(getfile)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1443(format_dict)\n",
      "        2    0.000    0.000    0.001    0.000 std.py:1283(fp_write)\n",
      "        2    0.000    0.000    0.002    0.001 std.py:345(print_status)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.sum}\n",
      "        1    0.000    0.000    0.000    0.000 adam.py:15(__init__)\n",
      "       15    0.000    0.000    0.000    0.000 threading.py:1118(_wait_for_tstate_lock)\n",
      "        2    0.000    0.000    0.000    0.000 eval_frame.py:221(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 grad_mode.py:182(__init__)\n",
      "       78    0.000    0.000    0.000    0.000 {built-in method unicodedata.east_asian_width}\n",
      "        2    0.000    0.000    0.000    0.000 eval_frame.py:442(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 iostream.py:443(_is_master_process)\n",
      "        3    0.000    0.000    0.000    0.000 _weakrefset.py:63(__iter__)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:555(__init__)\n",
      "        4    0.000    0.000    0.001    0.000 iostream.py:464(_schedule_flush)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:185(__format__)\n",
      "        2    0.000    0.000    0.000    0.000 _ops.py:447(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:84(_get_value)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:104(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:97(_dispatch_sqrt)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:399(_patch_step_function)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:285(format_interval)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:141(__exit__)\n",
      "       17    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        2    0.000    0.000    0.000    0.000 typing.py:352(inner)\n",
      "        2    0.000    0.000    0.000    0.000 _ops.py:687(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._C._set_grad_enabled}\n",
      "        1    0.000    0.000    0.000    0.000 _foreach_utils.py:14(_get_fused_kernels_supported_devices)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:567(_get_free_pos)\n",
      "        2    0.000    0.000    0.002    0.001 std.py:339(fp_write)\n",
      "        1    0.000    0.000    0.001    0.001 _tensor.py:907(__rsub__)\n",
      "        1    0.000    0.000    0.000    0.000 graph.py:825(number_of_nodes)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:276(_acquire_restore)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:53(_commit_removals)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:267(__exit__)\n",
      "        6    0.000    0.000    0.000    0.000 inspect.py:943(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 package_importer.py:692(_patched_getfile)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:144(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._are_functorch_transforms_active}\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:1446(current_thread)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:309(_cuda_graph_capture_health_check)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}\n",
      "        4    0.000    0.000    0.000    0.000 std.py:109(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:152(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:264(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen genericpath>:16(exists)\n",
      "        1    0.000    0.000    0.000    0.000 _weakrefset.py:110(remove)\n",
      "        1    0.000    0.000    0.002    0.002 _tensor.py:980(__iter__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method utcfromtimestamp}\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:309(disp_len)\n",
      "        4    0.000    0.000    0.000    0.000 eval_frame.py:192(innermost_fn)\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:27(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 functools.py:65(wraps)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'sub' of 're.Pattern' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:305(_text_width)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:287(helper)\n",
      "        1    0.000    0.000    0.000    0.000 _weakrefset.py:85(add)\n",
      "        2    0.000    0.000    0.000    0.000 skipfiles.py:205(check)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method nt.getpid}\n",
      "        4    0.000    0.000    0.000    0.000 std.py:112(__exit__)\n",
      "       16    0.000    0.000    0.000    0.000 threading.py:568(is_set)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method torch._C._dynamo.eval_frame.set_eval_frame}\n",
      "        1    0.000    0.000    0.001    0.001 std.py:1322(refresh)\n",
      "       42    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "       15    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'conj' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "        2    0.000    0.000    0.000    0.000 reportviews.py:185(__iter__)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:83(wrapper_setattr)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:118(disable_on_exception)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:132(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:283(ismodule)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:292(isclass)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:56(__eq__)\n",
      "        6    0.000    0.000    0.000    0.000 inspect.py:946(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:21(__enter__)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method torch.is_grad_enabled}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1207(_handle_fromlist)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:273(_release_save)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._C._get_privateuse1_backend_name}\n",
      "        1    0.000    0.000    0.000    0.000 _monitor.py:94(report)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1154(__hash__)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:197(_supports_unicode)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:279(_is_owned)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "        8    0.000    0.000    0.000    0.000 threading.py:1161(ident)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.is_complex}\n",
      "        4    0.000    0.000    0.000    0.000 utils.py:153(__eq__)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:570(<setcomp>)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1150(_comparable)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:1144(__del__)\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:17(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:378(isfunction)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:230(__call__)\n",
      "        6    0.000    0.000    0.000    0.000 _jit_internal.py:1109(is_scripting)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:183(_is_utf)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:39(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.abs}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:751(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:139(_tensor_or_tensors_to_tuple)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:87(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:466(isframe)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:480(iscode)\n",
      "        2    0.000    0.000    0.000    0.000 adam.py:296(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:43(__format__)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:300(ismethod)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function}\n",
      "        1    0.000    0.000    0.000    0.000 std.py:648(get_lock)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:456(istraceback)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:29(is_built)\n",
      "        2    0.000    0.000    0.000    0.000 decorators.py:141(graph_break)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 std.py:166(colour)\n",
      "        1    0.000    0.000    0.000    0.000 _foreach_utils.py:8(_get_foreach_kernels_supported_devices)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:225(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        4    0.000    0.000    0.000    0.000 _utils.py:841(is_compiling)\n",
      "        2    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}\n",
      "        4    0.000    0.000    0.000    0.000 eval_frame.py:205(enable_dynamic)\n",
      "        4    0.000    0.000    0.000    0.000 eval_frame.py:188(nothing)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:70(__getattr__)\n",
      "        1    0.000    0.000    0.000    0.000 reportviews.py:182(__len__)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:162(colour)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:213(_screen_shape_wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:124(annotate)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:757(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:754(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:340(_optimizer_step_code)\n",
      "        2    0.000    0.000    0.000    0.000 typing.py:2256(cast)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:1298(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method sys.audit}"
     ]
    }
   ],
   "source": [
    "%prun embedding, loss_history = deepWalk(graph=bc_dataset['graph'],  walks_per_vertex=5, walk_length=40, window_size=10,  embedding_size=128,num_neg=5,lr=1e-2,epochs=1,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a7be8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "207it [1:11:36, 20.75s/it]                         \n"
     ]
    }
   ],
   "source": [
    "embedding, loss_history = deepWalk(graph=bc_dataset['graph'], \n",
    "                                   walks_per_vertex=5, \n",
    "                                   walk_length=40,\n",
    "                                   window_size=10,\n",
    "                                   embedding_size=128,\n",
    "                                   num_neg=5,\n",
    "                                   lr=1e-2,\n",
    "                                   epochs=1,\n",
    "                                   batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "584b2bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGfCAYAAAD/BbCUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+70lEQVR4nO3dd3gUdeLH8c9uekKyIYSQBAIJEAgQSOhFUERFERS7YAN7wcKpv0Pvzu6J5c7Ts2A55VBEsGGBOxAUUESkhN5LIAESQoBkU8im7Pz+QONFEBLYzWx5v55nn0dmJ5nPPJNkP8585zsWwzAMAQAANBKr2QEAAIB/oXwAAIBGRfkAAACNivIBAAAaFeUDAAA0KsoHAABoVJQPAADQqCgfAACgUVE+AABAo6J8AACARhXY0C/47rvv9MILL2jlypXKy8vTzJkzdckll9S+bxiGnnjiCb311ls6fPiw+vbtq9dee01dunSp1/d3Op3at2+fIiMjZbFYGhoPAACYwDAMlZSUKDExUVbric9tNLh8lJWVKSMjQzfeeKMuv/zyY95//vnn9eKLL+rf//63OnTooKefflrnnXeetmzZosjIyJN+/3379ikpKamhsQAAgAfIzc1Vq1atTriO5XQeLGexWOqc+TAMQ4mJiRo/frwmTJggSXI4HGrRooWee+453X777Sf9nsXFxYqOjlZubq6ioqJONRoAAGhEdrtdSUlJKioqks1mO+G6DT7zcSLZ2dnKz8/X0KFDa5eFhITorLPO0pIlS45bPhwOhxwOR+2/S0pKJElRUVGUDwAAvEx9hky4dMBpfn6+JKlFixZ1lrdo0aL2vd+aOHGibDZb7YtLLgAA+Da33O3y29ZjGMbvNqGHH35YxcXFta/c3Fx3RAIAAB7CpZdd4uPjJR09A5KQkFC7vKCg4JizIb8ICQlRSEiIK2MAAAAP5tIzHykpKYqPj9e8efNql1VWVmrRokUaMGCAKzcFAAC8VIPPfJSWlmr79u21/87Oztbq1asVExOj1q1ba/z48XrmmWeUmpqq1NRUPfPMMwoPD9c111zj0uAAAMA7Nbh8rFixQmeffXbtv++//35J0pgxY/Tvf/9bf/zjH3XkyBHdddddtZOMff311/Wa4wMAAPi+05rnwx3sdrtsNpuKi4u51RYAAC/RkM9vnu0CAAAaFeUDAAA0KsoHAABoVJQPAADQqCgfAACgUflN+XA6DU3+IVuPfrHe7CgAAPg1l06v7sk25tn15KyNMgzp7LQ4nd0xzuxIAAD4Jb8585He0qabzkiRJD386TrZK6pMTgQAgH/ym/IhSQ8O7ajkZuHKt1for7M2mR0HAAC/5FflIyw4QM9fkSGLRZqxIlfzN+43OxIAAH7Hr8qHJPVJiam9/PLAx2u0t+iIyYkAAPAvflc+JGnCBWnKaGVT8ZEq3T0tS5XVTrMjAQDgN/yyfAQHWvXqNT0UFRqoVTlFen7OZrMjAQDgN/yyfEhSUky4XrgyQ5L0r8XZ+npDvsmJAADwD35bPiTp/C7xunng0fEfD368RrmHyk1OBACA7/Pr8iEdHf+RmRQte0W17v5wlapqGP8BAIA7+X35ODr+o7uiQgO1JrdIr3y73exIAAD4NL8vH5LUqmm4/nppV0nSawu2a+XuwyYnAgDAd1E+fnZRRqIuyUxUjdPQ/R+tVpmj2uxIAAD4JMrH/3hiZLpaRodp98FyPTVro9lxAADwSZSP/2ELC9Lfrzo6/fr05bmay+23AAC4HOXjN/q1babbzmwrSXr4s3UqKKkwOREAAL6F8nEc95/XQZ0SonSorFKPfr7B7DgAAPgUysdxhAQG6MWrMhRotWjOhnzNWc/lFwAAXIXy8Ts6JUTp9rOOXn559Iv1Kj5SZXIiAAB8A+XjBO4Zkqq2sREqKHHor7O5+wUAAFegfJxAaFCAnrmsqywW6aMVe/RZ1h6zIwEA4PUoHyfRr20z3TskVZL0p5nrtDnfbnIiAAC8G+WjHu49J1WDUmNVUeXUnVOzmP0UAIDTQPmohwCrRS+P6q4EW6iyC8v0NOM/AAA4ZZSPeoqJCK6d/fTDZbmat3G/2ZEAAPBKlI8GGNAuVrcMTJEkPfTpWh0ocZicCAAA70P5aKAHz++otPhIHSyr1B9mrFaN0zA7EgAAXoXy0UAhgQF6ZXR3hQUFaPH2Qr2+YLvZkQAA8CpuKR8lJSUaP3682rRpo7CwMA0YMEDLly93x6ZMkdoiUk+O7CJJ+sf8rVq686DJiQAA8B5uKR+33HKL5s2bp/fff1/r1q3T0KFDde6552rv3r3u2JwpruyVpMt6tJTTkO6elqV9RUfMjgQAgFewGIbh0kELR44cUWRkpL744gsNHz68dnlmZqZGjBihp59++oRfb7fbZbPZVFxcrKioKFdGc7nyympdPulHbcqzq2tLmz6+o79CgwLMjgUAQKNryOe3y898VFdXq6amRqGhoXWWh4WFafHixces73A4ZLfb67y8RXhwoN66vqeahgdp3d5i/emzdXJxlwMAwOe4vHxERkaqf//+euqpp7Rv3z7V1NRo6tSp+umnn5SXl3fM+hMnTpTNZqt9JSUluTqSWyXFhOu1a3sowGrRZ6v26sNluWZHAgDAo7llzMf7778vwzDUsmVLhYSE6J///KeuueYaBQQce0ni4YcfVnFxce0rN9f7PrwHtIvV/53fUZL0+FcbtH5vscmJAADwXG4pH+3atdOiRYtUWlqq3NxcLVu2TFVVVUpJSTlm3ZCQEEVFRdV5eaPbBrXVOWlxqqx2aty0LJVUVJkdCQAAj+TWeT4iIiKUkJCgw4cPa+7cuRo5cqQ7N2cqq9Wiv1+VoZbRYdp9sFyPfbHB7EgAAHgkt5SPuXPnas6cOcrOzta8efN09tlnq2PHjrrxxhvdsTmPER0erJdHZcpqkT5btVdfrtlndiQAADyOW8pHcXGxxo0bp7S0NN1www0aOHCgvv76awUFBbljcx6lV3KM7j67vSTpzzPXaS/zfwAAUIfL5/k4Xd40z8fvqapx6so3ftTq3CL1aB2tGbf3V1AAM9kDAHyXqfN8QAoKsOqfo7orMjRQWTlFeva/m82OBACAx6B8uEnrZuH625UZkqR3Fmdrzvpj5zgBAMAfUT7c6Pwu8bp10NHbi//v47XaVVhmciIAAMxH+XCzP16Qpl5tmqrEUa27PshSRVWN2ZEAADAV5cPNggKseuWa7oqJCNbGPLue+Ir5PwAA/o3y0QgSbGF6eVSmLBbpw2W5mrWW+T8AAP6L8tFIBqU217jBR+f/ePizddpzuNzkRAAAmIPy0YjuOzdVmUnRKqmo1v0z1qjG6VFTrAAA0CgoH40oKMCql0dlKiI4QMt2HdJzc5j/AwDgfygfjaxNswg9e3k3SdJb3+3U9GU5JicCAKBxUT5McFFGosafmypJ+svn67Vke6HJiQAAaDyUD5Pcd06qRmYmqtpp6N7pq1VY6jA7EgAAjYLyYRKLxaLnLu+mji0iVVjq0IRP1srDnvEHAIBbUD5MFBoUoJdHZyo40KpvNhfo/aW7zY4EAIDbUT5MlhYfpYeHpUmS/jp7k7buLzE5EQAA7kX58ABjByRrcMfmclQ7de+Hq3j+CwDAp1E+PIDFYtELV2QotkmwNueXMP8HAMCnUT48RPPIEL1wRYYkafIPu7RwS4HJiQAAcA/Khwc5Oy1OYwckS5Ie/Hgtt98CAHwS5cPDPDQsrfb22//7eA233wIAfA7lw8OEBgXon6O7KzjQqgVbDnD7LQDA51A+PFDH+Mja228n/mezdhWWmZwIAADXoXx4qDH9k9W/bTMdqarR/32yRjVOLr8AAHwD5cNDWa0WPX9FN0UEB2j5rsN6d3G22ZEAAHAJyocHS4oJ1yMjOkuSnpuzWT/uOGhyIgAATh/lw8Nd3Tup9um3d32wUjkHy82OBADAaaF8eLhfnn7brZVNh8urdOt7K1ReWW12LAAAThnlwwuEBgXoret7qXlkiLbsL9HjX24wOxIAAKeM8uEl4m2henlUpiwW6aMVe/TF6r1mRwIA4JRQPrzIgHaxumdIqiTpzzPXa/dB5v8AAHgfyoeXuXdIe/VJjlGpo1rjZ6xWdY3T7EgAADQI5cPLBAZY9Y9RmYoMDdSqnCK9umC72ZEAAGgQyocXahkdpqcvSZckvfLtdmXlHDY5EQAA9Uf58FIjM1tqZGaiapyG/jBjtcoc3H4LAPAOLi8f1dXV+stf/qKUlBSFhYWpbdu2evLJJ+V0MjbB1Z4cma5EW6h2HyzXU7M2mh0HAIB6cXn5eO655/TGG2/o1Vdf1aZNm/T888/rhRde0CuvvOLqTfk9W1iQ/n7V0dtvpy/P1dwN+WZHAgDgpFxePn788UeNHDlSw4cPV3Jysq644goNHTpUK1ascPWmIKl/u2a67cy2kqSHPl2rvOIjJicCAODEXF4+Bg4cqG+++UZbt26VJK1Zs0aLFy/WhRdeeNz1HQ6H7HZ7nRca5v7zOii9ZZQOl1fpvg+5/RYA4NlcXj4mTJig0aNHKy0tTUFBQerevbvGjx+v0aNHH3f9iRMnymaz1b6SkpJcHcnnhQQG6NXRPdQkJFDLdh3SS/O3mR0JAIDf5fLyMWPGDE2dOlXTpk1TVlaWpkyZor/97W+aMmXKcdd/+OGHVVxcXPvKzc11dSS/kBwboYmXdZUkvbZwu37aedDkRAAAHJ/FMAzDld8wKSlJDz30kMaNG1e77Omnn9bUqVO1efPmk3693W6XzWZTcXGxoqKiXBnNL0z4ZK1mrMhV29gI/ee+QQoNCjA7EgDADzTk89vlZz7Ky8tltdb9tgEBAdxq20j+NLyT4iJDtLOwTK8x+ykAwAO5vHxcdNFF+utf/6rZs2dr165dmjlzpl588UVdeumlrt4UjsMWFqQnLu4iSZq0cIc25zOAFwDgWVx+2aWkpESPPPKIZs6cqYKCAiUmJmr06NF69NFHFRwcfNKv57LL6TMMQ7e/v1Jfb9yvtPhIfT7uDC6/AADcqiGf3y4vH6eL8uEaBSUVuvDlxSosdWh0nyRNvKyb2ZEAAD7M1DEf8AxxkaF6edTR2U8/XJarL1bvNTsSAACSKB8+7Yz2sbpnSKok6U+frdPOA6UmJwIAgPLh8+47J1X92saorLJG46atUkVVjdmRAAB+jvLh4wKsFr08qruaRQRrU56dp98CAExH+fADLaJC9Y+rj47/+OCnHH21Zp/ZkQAAfozy4SfO7NBc4wa3lyQ9/Nk6ZReWmZwIAOCvKB9+ZPy5qeqTEqNSR7XGfZDF+A8AgCkoH34kMMCqf47qrpiIYG3Ms+svn6+Xh03zAgDwA5QPPxNvOzr/h9UifbJyjyb/sMvsSAAAP0P58EODUpvrTxd2kiT99T+btHhbocmJAAD+hPLhp24emKLLe7RSjdPQHz5arcNllWZHAgD4CcqHn7JYLPrrpelqH9dEB0ocevTLDWZHAgD4CcqHHwsNCtDfr8xQgNWir9bs06y1zP8BAHA/yoefy0iK1rjB7SRJf/l8vXIPlZucCADg6ygf0N1DUpXRyqai8ird9v5KlVdWmx0JAODDKB9QcKBVb1zfU7FNjj7/5Y+frGX+DwCA21A+IElKsIXp9Wt7KtBq0ay1eXrzu51mRwIA+CjKB2r1SYnRYxd3kSQ9N2ezFm09YHIiAIAvonygjuv6ttao3kkyDOmeaVnaxQPoAAAuRvlAHRaLRU+M7KLuraNlr6jWbe+vUJmDAagAANehfOAYIYEBeuO6nmoeGaKt+0v1wEdrGIAKAHAZygeOq0VUqN64rqeCAiyasyFfry3YbnYkAICPoHzgd/Vs01RPjUyXJL04b6tW7j5kciIAgC+gfOCERvVprUu7t5TTkMbPWK2SiiqzIwEAvBzlAyf1xMguahkdptxDR/T4lxvNjgMA8HKUD5xUVGiQXhqVKatF+jRrj6YvyzE7EgDAi1E+UC+9k2P0h3M7SJIe+WK9Vuxi/AcA4NRQPlBvdw9prwu7xquqxtAdU1dqX9ERsyMBALwQ5QP1ZrFY9LcrM9QpIUqFpZW6/6PVcjqZ/wMA0DCUDzRIeHCgJl3bQ2FBAVq685De/SHb7EgAAC9D+UCDJcdG6JERnSVJz8/Zos35dpMTAQC8CeUDp2R0nySdkxanyhqn7pqapaLySrMjAQC8BOUDp8Risei5K7qpZXSYdhaW6Y6pK1VZ7TQ7FgDAC1A+cMpim4TonbG91CQkUEt3HtKfZ67jAXQAgJNyeflITk6WxWI55jVu3DhXbwoeIC0+Sq9e010BVos+XrlHU5fuNjsSAMDDubx8LF++XHl5ebWvefPmSZKuvPJKV28KHmJwxzg9dEGaJOnJWRu1KuewyYkAAJ7M5eWjefPmio+Pr33NmjVL7dq101lnneXqTcGD3DIoRcPSj05AdtcHWTpY6jA7EgDAQ7l1zEdlZaWmTp2qm266SRaL5bjrOBwO2e32Oi94H4vFouev6Ka2sRHKK67QfdNXq4YJyAAAx+HW8vH555+rqKhIY8eO/d11Jk6cKJvNVvtKSkpyZyS4UWRokN64vqfCggK0eHuhXpq/1exIAAAPZDHceHvC+eefr+DgYH311Ve/u47D4ZDD8espervdrqSkJBUXFysqKspd0eBGX6zeq/umr5Yk/euGXjq3cwtzAwEA3M5ut8tms9Xr89ttZz52796t+fPn65ZbbjnheiEhIYqKiqrzgncbmdlSY/q3kSSNn7FaW/eXmJwIAOBJ3FY+Jk+erLi4OA0fPtxdm4AH+/PwzuqbEqNSR7VunrJch8qYARUAcJRbyofT6dTkyZM1ZswYBQYGumMT8HDBgVa9cV1PtY4JV+6hI7rrg5UMQAUASHJT+Zg/f75ycnJ00003uePbw0s0jQjWO2N6KSL46BNw3/xuh9mRAAAewC3lY+jQoTIMQx06dHDHt4cXSW0Rqccu7iJJevHrrVq7p8jcQAAA0/FsF7jdlT1b6cKu8ap2Gho/fbXKK6vNjgQAMBHlA25nsVj0zKVdFR8Vqp2FZXpq1iazIwEATET5QKOIDg/Wi1dlyGKRPlyWo6835JsdCQBgEsoHGs2A9rG6dVBbSdKET9eqwF5hciIAgBkoH2hUDwztoM4JUTpcXqUHPl4jJ7ffAoDfoXygUYUEBuifozMVEmjV99sK9e8lu8yOBABoZJQPNLr2cZH6y/BOkqRn52zW5nyeZAwA/oTyAVNc16+NhqTFqbLaqbs+yFJxeZXZkQAAjYTyAVNYLBY9f0U3JdpCtfNAmcZNy1JVjdPsWACARkD5gGlim4To7TG9FB4coMXbC/XkVxvNjgQAaASUD5iqS6JNL12dKYtFen/pbn2WtcfsSAAAN6N8wHRDu8TrvnNSJUl/nrle2wtKTE4EAHAnygc8wj1DUjWwfayOVNXorg+yeP4LAPgwygc8QoDVon9cnanmkSHaur9Uj36xwexIAAA3oXzAYzSPDNEro7vLapE+WblHH6/INTsSAMANKB/wKP3aNtP953WQJD3yxXptyWf8BwD4GsoHPM5dg9trUGqsKqqcuuuDlSpzMP4DAHwJ5QMex2q16KWrM9UiKkQ7DpTpL5+vl2HwADoA8BWUD3ikZk1C9MroHgqwWjRz1V7NWM74DwDwFZQPeKw+KTF6YOjR8R+PfrFBK3cfMjkRAMAVKB/waHec2U7nd2mhyhqnbntvpXIPlZsdCQBwmigf8GjWn+f/6JIYpYNllbp5ynKVMgAVALwa5QMeLzw4UO+M6a0WUUcnIPvzzHUMQAUAL0b5gFeIt4XqtWuODkD9YvU+TWcAKgB4LcoHvEav5Bj93/kdJUmPfblBG/YVm5wIAHAqKB/wKrcNaqshaXGqrD46ALWw1GF2JABAA1E+4FWsVov+cVWmUmIjtLfoiO6culKV1U6zYwEAGoDyAa9jCw/S2zf0UmRooJbvOqxHmAEVALwK5QNeqX1ck9on4M5YkavJP+wyOxIAoJ4oH/BagzvG6U8XdpIkPT17o77besDkRACA+qB8wKvdPDBFV/ZsJach3T0tSzkHmQEVADwd5QNezWKx6OlL09WjdbTsFdW6a9pKVVTVmB0LAHAClA94vZDAAL16TQ81DQ/S+r12/XX2JrMjAQBOgPIBn5AYHaZ/XJ0pi0V6f+lufbyCGVABwFO5pXzs3btX1113nZo1a6bw8HBlZmZq5cqV7tgUUGtwxzjdMyRVkvTwZ+u0ZHuhyYkAAMfj8vJx+PBhnXHGGQoKCtJ///tfbdy4UX//+98VHR3t6k0Bxxh/TqouykhUtdPQ7VNXatv+ErMjAQB+I9DV3/C5555TUlKSJk+eXLssOTnZ1ZsBjstqteiFK7opr+iIVuw+rFvfW6Ev7h4oW1iQ2dEAAD9z+ZmPL7/8Ur169dKVV16puLg4de/eXW+//fbvru9wOGS32+u8gNMRGhSgt27opZbRYdp1sFwPfLRaTiczoAKAp3B5+di5c6cmTZqk1NRUzZ07V3fccYfuvfdevffee8ddf+LEibLZbLWvpKQkV0eCH4qJCNYb1/VUcKBV8zcV6NUF282OBAD4mcVw8UMxgoOD1atXLy1ZsqR22b333qvly5frxx9/PGZ9h8Mhh+PXJ5Pa7XYlJSWpuLhYUVFRrowGP/TRilz98ZO1kqSXR2VqZGZLkxMBgG+y2+2y2Wz1+vx2+ZmPhIQEde7cuc6yTp06KScn57jrh4SEKCoqqs4LcJWreiXp5oEpkqQHP16jJTu4AwYAzOby8nHGGWdoy5YtdZZt3bpVbdq0cfWmgHr584WdNLxrgqpqDN3+/kptyecOGAAwk8vLxx/+8ActXbpUzzzzjLZv365p06bprbfe0rhx41y9KaBerFaL/n5VhnonN1VJRbXGTl6m/OIKs2MBgN9yefno3bu3Zs6cqQ8//FDp6el66qmn9NJLL+naa6919aaAegsNCtDbN/RSu+YRyiuu0NjJy2SvqDI7FgD4JZcPOD1dDRmwAjRU7qFyXTZpiQ6UODQoNVaTx/ZWYABPGQCA02XqgFPAkyXFhGvy2N4KCwrQ99sK9dSsjWZHAgC/Q/mA30lvadM/rs6UJE35cbfe/3GXqXkAwN9QPuCXLkiP1x8v6ChJenLWRq3OLTI3EAD4EcoH/NadZ7XTsPR4VdUYGvdBlorLGYAKAI2B8gG/ZbFY9NwV3dQ6Jlx7i47ogY/X8AwYAGgElA/4tajQIL12TQ8FB1g1f9N+vfzNNrMjAYDPo3zA73VtZdPTl6RLkl7+Zptmrd1nciIA8G2UD0DSVb2TdMv/PANm3Z5ikxMBgO+ifAA/e/jCTjqrQ3NVVDl163srVGBnCnYAcAfKB/CzAKtFr1zTXe2aRyjfXqFb31+piqoas2MBgM+hfAD/Iyo0SO+M6a3o8CCtyS3SQ5+ulYc9gQAAvB7lA/iN5NgIvX5tDwVaLfp89T5NWrTD7EgA4FMoH8BxDGgXq8cv7iJJemHuFn29Id/kRADgOygfwO+4rl8b3dC/jQxDum/6aqZgBwAXoXwAJ/DIiM46s0NzHamq0U3/Xq6dB0rNjgQAXo/yAZxAUIBVk67toW6tbDpUVqkb3l3GLbgAcJooH8BJRIQE6t2xvZXcLFx7Dh/RmMnLZa/gIXQAcKooH0A9xDYJ0Xs39VVskxBtyrPrtvdWyFHNHCAAcCooH0A9tW4Wrn/f2FtNQgK1dOch3T+Dp+ACwKmgfAANkN7Spreu76mgAItmr8vTk7M2MgkZADQQ5QNooAHtY/XiVZmSpH8v2aXXFzIJGQA0BOUDOAUXZSTq0RGdJR2dhOzjFbkmJwIA70H5AE7RTQNTdMdZ7SRJD322Tt9u3m9yIgDwDpQP4DRMuKCjLuvRUjVOQ3d9kKWVuw+ZHQkAPB7lAzgNFotFz13eTWd3bK6KKqdunLxcm/LsZscCAI9G+QBOU1CAVa9f21O92jSVvaJa17+zTLsPlpkdCwA8FuUDcIGw4AC9M7a3OiVEqbDUoeve+Un7mYYdAI6L8gG4iC0sSFNu6q02zcKVe+iIbnhnmYrKK82OBQAeh/IBuFBcZKim3txXLaJCtGV/ia6ngADAMSgfgIslxYTr/Zv7KiYiWOv2Fuuat3/S4TIKCAD8gvIBuEGHFpH68NZ+im0SrI15do1+e6kOljrMjgUAHoHyAbhJx/hITb+tn5pHhmhzfolGv71UB0ooIABA+QDcqH1cpGbc1k/xUaHaur9Uo976UYWcAQHg5ygfgJu1bd5EM27vp0RbqHYcKNMtU1boSGWN2bEAwDQuLx+PP/64LBZLnVd8fLyrNwN4lTbNIvT+LX0VHR6k1blFGj9jlWqchtmxAMAUbjnz0aVLF+Xl5dW+1q1b547NAF6lXfMmeuv6XgoOsGruhv169Iv1MgwKCAD/45byERgYqPj4+NpX8+bN3bEZwOv0SYnRi1dnyGKRPvgpR0/N2kQBAeB33FI+tm3bpsTERKWkpGjUqFHauXPn767rcDhkt9vrvABfNqJbop67rJsk6d0fsvX83C0UEAB+xeXlo2/fvnrvvfc0d+5cvf3228rPz9eAAQN08ODB464/ceJE2Wy22ldSUpKrIwEe56reSXrqknRJ0qSFO/TPb7abnAgAGo/FcPP/cpWVlaldu3b64x//qPvvv/+Y9x0OhxyOX289tNvtSkpKUnFxsaKiotwZDTDdv77fqadnb5IkTbggTXcObmdyIgA4NXa7XTabrV6f34HuDhMREaGuXbtq27Ztx30/JCREISEh7o4BeKRbBrVVZY1Tz8/ZoufmbFZIoFU3DUwxOxYAuJXb5/lwOBzatGmTEhIS3L0pwCvdNbi97jsnVZL05KyNmrp0t8mJAMC9XF4+HnzwQS1atEjZ2dn66aefdMUVV8hut2vMmDGu3hTgM8afm6o7zjp6yeUvn6/XxytyTU4EAO7j8ssue/bs0ejRo1VYWKjmzZurX79+Wrp0qdq0aePqTQE+w2KxaMIFHeWortHkH3ZpwqdrFRxo1cjMlmZHAwCXc3n5mD59uqu/JeAXLBaLHh3RWY5qp6b9lKP7P1qjQKtVw7txyRKAb+HZLoAHsVgsenpkuq7o2Uo1TkN3f5il937cZXYsAHApygfgYaxWi567vJuu69dahiE9+sUGPT9nMxORAfAZlA/AAwVYLXpqZLoeHNpBkvT6wh164OM1qqpxmpwMAE4f5QPwUBaLRXcPSdXzl3dTgNWiz7L26uYpK1TmqDY7GgCcFsoH4OGu6p2kt2/oqbCgAH239YBGvbVUB0ocJ/9CAPBQlA/ACwxJa6EPb+unmIhgrdtbrMsnLdGuwjKzYwHAKaF8AF4iMylan9zRX0kxYco5VK4r3vhRG/fxFGgA3ofyAXiRts2b6NM7B6hTQpQKSx26+q0ftSz7kNmxAKBBKB+Al4mLDNX02/qpd3JTlVRU6/p3ftK3m/ebHQsA6o3yAXghW1iQ3rupr4akxclR7dRt763U56v2mh0LAOqF8gF4qbDgAL15fU9dkpmoaqeh8TNW65n/bGIuEAAej/IBeLGgAKtevCpTtw5KkSS99d1OXfXmj9pbdMTkZADw+ygfgJezWi368/DOeuO6nooMDdSqnCJd+PL3+mYT40AAeCbKB+AjLkiP13/uHaSMVjYVH6nSzVNWcBkGgEeifAA+JCkmXB/fMUA3npEsicswADwT5QPwMcGBVj12URcuwwDwWJQPwEdxGQaAp6J8AD7sl8swN53B3TAAPAflA/BxwYFWPXpRZ715PZdhAHgGygfgJ87vwmUYAJ6B8gH4keNdhhn91lIdKHGYnAyAP6F8AH7mt5dhVuw+rJGvLtb6vcVmRwPgJygfgJ86v0u8vhh3htrGRmhfcYUun7RE7/24S4ZhmB0NgI+jfAB+rG3zJpo57gwN7thcjmqnHv1ig8ZMXq799gqzowHwYZQPwM/ZwoL07pjeevyizgoJtOq7rQd0/kvf6T/r8syOBsBHUT4AyGq1aOwZKZp1z0Clt4xSUXmV7vogS3dPy+IsCACXo3wAqJXaIlKf3XmG7j67vawWadbaPJ3z90Wa/EM2Y0EAuAzlA0AdwYFWPXh+R31590BlJkWr1FGtJ77aqLs/XKXyymqz4wHwAZQPAMeV3tKmz+4coMcv6qxAq0Wz1+bp8kk/antBidnRAHg5ygeA3/XLWJBpt/ZTbJNgbcqz68J/LtakhTtUzcyoAE4R5QPASfVJidGsewbp7I7NVVnt1HNzNuvyN37Utv2cBQHQcJQPAPUSbwvVu2N7629XZigyNFBrcos0/J+L9frC7ZwFAdAglA8A9WaxWHRFz1aa94ezNCQtTpU1Tj0/Z4sun7REWzkLAqCeKB8AGizeFqp3xvTS36/MUFRooNbsKdaIfy7Waws4CwLg5NxePiZOnCiLxaLx48e7e1MAGpHFYtHlPVtp3v1n6Zyfz4K8MHeLLpu0RFvyOQsC4Pe5tXwsX75cb731lrp16+bOzQAwUYuoUP1rTC+9eNXRsyBr9xTrolc4CwLg97mtfJSWluraa6/V22+/raZNm7prMwA8gMVi0WU9jj0LMuKVxfpxx0Gz4wHwMG4rH+PGjdPw4cN17rnnnnA9h8Mhu91e5wXAO/1yFuQfV2coOjxIm/NLNPrtpRr3QZb2HC43Ox4AD+GW8jF9+nRlZWVp4sSJJ1134sSJstlsta+kpCR3RALQSCwWiy7t3koLHhis6/u1kdUizV539BkxL83fqiOVNWZHBGAyl5eP3Nxc3XfffZo6dapCQ0NPuv7DDz+s4uLi2ldubq6rIwEwQdOIYD11Sbpm3TNIfVNi5Kh26qX523Tui4s0e20eD6oD/JjFcPFfgM8//1yXXnqpAgICapfV1NTIYrHIarXK4XDUee+37Ha7bDabiouLFRUV5cpoAExiGIZmr8vTM7M3aV9xhSRpUGqsnr28m1pGh5mcDoArNOTz2+Xlo6SkRLt3766z7MYbb1RaWpomTJig9PT0E3495QPwXUcqa/TGoh2atGiHKqudiggO0P1DO+ravq0VGvT7/1MCwPOZWj6OZ/DgwcrMzNRLL7100nUpH4Dv23GgVBM+WasVuw9LkmKbBOvWQW01ZkAyJQTwUg35/GaGUwCNrl3zJvro9v6aeFlXtYwOU2FppSb+d7OG/uM7zdu4n/EggI9rlDMfDcGZD8C/VNU49fmqvfrb11u03+6QJA3u2FyPjuists2bmJwOQH153GWXhqB8AP6pzFGtVxds17++36mqGkNBARbdPLCt7hnSXhEhgWbHA3ASlA8AXmvngVI9OWujFm45IElqERWih4d10sUZibJaLSanA/B7KB8AvJphGPpmU4GenLVROYeOzozaJTFKEy5I06DUWFkslBDA01A+APiEiqoavbM4W5MW7lCpo1qSNKBdM024IE0ZSdHmhgNQB+UDgE85VFapV7/drqlLd6vy5yflXtg1Xg8O7cigVMBDUD4A+KTcQ+X6x/ytmrlqrwxDCrBaNKp3ku4/r4OaNQkxOx7g1ygfAHza5ny7np+zRd9uLpAkRYYG6r5zUnVdvzZMUgaYhPIBwC8s3XlQT361URvz7JKkZhHBumlgiq7r10a2sCCT0wH+hfIBwG/UOA19sjJXr3y7XXsOH5EkRYYE6tp+bXTTwGTFRZ786doATh/lA4Dfqa5x6qu1+zRp4Q5t3V8qSQoOtOqqXq10+5ntlBQTbnJCwLdRPgD4LafT0DebC/T6wu1alVMk6ejA1Iu6JejOwe3VMT7S3ICAj6J8APB7hmFo6c5Den3hdn2/rbB2+bmd4nTn4Pbq2aapiekA30P5AID/sW5PsSYt2q7/rs/XL3/xeic31S2D2urcTi0UwLTtwGmjfADAcew4UKo3F+3QzFV7VVVz9E9fcrNw3TQwRVf0bKXwYB5gB5wqygcAnEB+cYWm/LhLHyzdLXvF0WnbbWFBurZva40ZkKwWUdwhAzQU5QMA6qHMUa1PVu7Ruz9ka/fBow+wCwqw6KKMRN0ysK06J/I3CKgvygcANECN09C8jfv1zuKdWr7rcO3yvikxGt2ntS5Ij2fmVOAkKB8AcIpW5xbpX9/v1H/X56vGefTPY7OIYN17TqpG92mt4ECryQkBz0T5AIDTtK/oiD5akauPludqX3GFpKODU+86u70uyWxJCQF+g/IBAC5SVePUjOW5emn+VhWWVkqSEmyhunlgikb3aa2IEO6QASTKBwC4XKmjWtN+2q1/fZ+tghKHJCk6PEjX9W2jq3olqXUzpm+Hf6N8AICbVFTVaOaqvXpz0Q7t+vkOGUka0K6ZruqVxOBU+C3KBwC4WY3T0NwN+fpwWY4Wby+snTk1KjRQIzNb6ureSUpvaTM3JNCIKB8A0Ij2HC7XJyv36OMVe7S36Ejt8oxWNt1+Vjud3yWeKdzh8ygfAGACp9PQDzsKNWN5rr7esF+VNU5JUqumYRqZmaiRmS3VoQVP1YVvonwAgMkKSx1678fdeu/HXSoqr6pdnhYfqYsyEjUyM1GtmjJIFb6D8gEAHuJIZY3mbdqvL1fv06KtBbUPtJOkfm1jdHmPVhrWNUFNuGUXXo7yAQAeqLi8SnM25OnzVfu0NPtg7SDVsKAAXZAer8t7tFL/ds0YHwKvRPkAAA+3t+iIZmbt0adZe5VdWFa7PMEWqosyEnVRt0Slt4ySxUIRgXegfACAlzAMQ6tyi/Tpyj36as0+2Suqa99LbhZ+tIhkJDJQFR6P8gEAXqiiqkYLtxToqzV5+mbzflVUOWvf69CiiS7qlqgRGYlKiY0wMSVwfJQPAPByZY5qzd+0X1+tyTtmoGrXljZdlJGg4d0S1TI6zMSUwK8oHwDgQ4rLqzR3Y75mrc3TD9sLVeP89c92n+QYje6bpGHpCUzrDlNRPgDARx0sdei/6/P11Zp9WrbrUO0dM9HhQbqiRytd07e12jZvYm5I+CVTy8ekSZM0adIk7dq1S5LUpUsXPfrooxo2bFi9vp7yAQD1k19coY9W5Gr6shztK66oXd6jdbQuykjUhV0T1CIq1MSE8Cemlo+vvvpKAQEBat++vSRpypQpeuGFF7Rq1Sp16dLlpF9P+QCAhqlxGlq4pUDTfsrRgi0F+p+rMuqSGKUhaXE6Oy1OGa2imUMEbuNxl11iYmL0wgsv6Oabbz7pupQPADh1++0Vmr02T7PW7tOq3CL971/4mIhgnd0xTud1bqGzOjRXWDBjROA6HlM+ampq9PHHH2vMmDFatWqVOnfufMw6DodDDoej9t92u11JSUmUDwA4TYWlDi3ackDfbinQd1sOqMTx6xwikSGBGpGRqKt6tVJmUjSTmeG0mV4+1q1bp/79+6uiokJNmjTRtGnTdOGFFx533ccff1xPPPHEMcspHwDgOlU1Ti3fdUjfbCrQ3A352nP4SO17qXFNdFWvJF3SvaWaR4aYmBLezPTyUVlZqZycHBUVFenTTz/Vv/71Ly1atIgzHwDgAZxOQz9lH9LHK3L1n/V5tZOZBVotOjstTiO6JWhwxzjZwoJMTgpvYnr5+K1zzz1X7dq105tvvnnSdRnzAQCNx15RpVlr8vTxylytyimqXR5otahv2xid16mFzunUQkkx4eaFhFdoyOd3ozzD2TCMOmc3AACeISo0SNf0ba1r+rbWtv0lmrlqr+Zt3K9tBaX6YftB/bD9oB7/aqPS4iM1tHMLndu5hbq2tDFGBKfF5Wc+/vSnP2nYsGFKSkpSSUmJpk+frmeffVZz5szReeedd9Kv58wHAJhvV2GZ5m/ar6837teKXYfq3L4bHxWq4d0SdE3f1mrHhGb4mamXXW6++WZ98803ysvLk81mU7du3TRhwoR6FQ+J8gEAnuZwWaW+3Vyg+Zv2a9HWAyqvrKl9r09KjEZmJurC9AQ1jQg2MSXM5nFjPhqC8gEAnquiqkaLtxVq+vIcfbv51wnNggIsurBrgsYOSFb31k3NDQlTUD4AAG63r+iIvlyzT1+s3qdNefba5e2aR+iC9Hid06mFurW0KTDAamJKNBbKBwCgUa3dU6QpS3brq7X7VFntrF0eGRqo/m2baVBqrM5oH6uU2AgGq/ooygcAwBT2iiot2Hx0IrPF2wplr6iu837L6DCd0b6ZzuoQpzM7xCoylLlEfAXlAwBguhqnofV7i7V4e6EWbyvUyt2HVVnz61mRoACL+rVtpnPS4phLxAdQPgAAHqe8slrLdx3W91sP6NvNBdpZWFbn/bT4SJ3TKU7928aqaysbM6x6GcoHAMDj7ThQqm827df8TQXHzCUiSektozS8a6KGpcerTbNwxop4OMoHAMCrHC6r1MKtBVqw+YBW5xYp51B5nfejw4OUnmjTwNRYDUmLU2pcE8qIh6F8AAC8WmGpQ/M27teXq/dp+a5Dqv7NaZFWTcN0TlqchnRqof5tmyk4kNt5zUb5AAD4jIqqGm3bX6qsnMNasKVAS3YcrHM7b5OQQA3u2FzndW6hs9PiFMUdNKagfAAAfFZ5ZbWWbD+obzYX6JtN+1VQ8uuDS4MCLMpMilbflGbq2zZGPds0VXhwozxD1e9RPgAAfsHpNLRmT5HmbTz6ELztBaV13g+0WtS1lU19UmLUL6WZeiU3ZW4RN6F8AAD80u6DZVq686B+2nlIP2Uf0t6iI3Xet1qkLok29U2JUd+2zdQnOUa2cMqIK1A+AACQlHuoXMuyD+mn7IP6KfuQdh+sexeNxSJ1bBGpfm2bqW9KjPqkxKhZkxCT0no3ygcAAMeRX1yhn7IPaunOQ1qWfVA7DpQds077uCbqndxUvZNj1Ds5Rq2ahnFbbz1QPgAAqIcDJY5fz4zsPKQt+0uOWSfRFqqBqbEalNpcZ7SPVUxEsAlJPR/lAwCAU3C4rFIrdh/W8l2HtCz7kNbvLa4zx4jFIqUn2jTo5zLSs01T5hj5GeUDAAAX+OV5NIu3HdD32wq1Ob/umZHw4AD1a9tMA9vHqldyU3VKiFJQgH+WEcoHAABuUGCv0OLthfp+W6G+33ZAhaWVdd4PDbKqW6to9WjdVD1aR6tHm6aK9ZMBrJQPAADczOk0tDm/RN9vO6AlOw5qVc5h2Suqj1mvTbNw9U6OUZ/ko3fT+OpD8igfAAA0MqfT0M7CUmXtLlJWzmFl5RzWtoJS/fZTNi4yRL1TYtQ3JUY9WjdVaosmCgkMMCe0C1E+AADwAPaKKmX9zwDWNbnFqqxx1lkn0GpRu+ZNlJYQqbT4KGUmRat762iFBnlXIaF8AADggSqqarQ6t0jLs4/OwLpmT5FKjnOpJijAooxW0erz88RnvZJj1CTEs59RQ/kAAMALGIahvOIKbc63a1NeiTbm2bVi1yHttzvqrGe1SOktbbXjRnonx6iph803QvkAAMBLGYahnEPl+in7UO0EaLmHjhyzXlp8ZO2ZkT7JMYqLCjUh7a8oHwAA+JB9RUe0fNeh2kLy26f3SlJKbIT6JMeob9ujhaRV0/BGzUj5AADAhxWWOmrHjSzLPqRN+fZj7qppGR1We4mmS2KUOrSIVFiw+waxUj4AAPAjxUeqtHL3If2082ghWbe3WDXOuh/vVouUHBuhTglR6hQfqZsGpig82HWDWCkfAAD4sTJHtVblFGlZ9kFl5RRpU55dB8t+nY01ONCqjU+cr0AXTgXfkM9vz75vBwAANFhESKAGpsZqYGps7bKCkgptzivRpjy7SiqqXVo8GoryAQCAH4iLDFVcZKjO7NDc7Cjyz0fvAQAA01A+AABAo6J8AACARkX5AAAAjcrl5WPixInq3bu3IiMjFRcXp0suuURbtmxx9WYAAICXcnn5WLRokcaNG6elS5dq3rx5qq6u1tChQ1VWVubqTQEAAC/k9knGDhw4oLi4OC1atEhnnnnmSddnkjEAALyPR00yVlxcLEmKiYk57vsOh0MOx6+PDrbb7e6OBAAATOTWAaeGYej+++/XwIEDlZ6eftx1Jk6cKJvNVvtKSkpyZyQAAGAyt152GTdunGbPnq3FixerVatWx13neGc+kpKSuOwCAIAX8YjLLvfcc4++/PJLfffdd79bPCQpJCREISEh7ooBAAA8jMvLh2EYuueeezRz5kwtXLhQKSkprt4EAADwYi4vH+PGjdO0adP0xRdfKDIyUvn5+ZIkm82msLAwV28OAAB4GZeP+bBYLMddPnnyZI0dO/akX19cXKzo6Gjl5uYy5gMAAC/xy5jNoqIi2Wy2E67rlssup6OkpESSuOsFAAAvVFJSctLy4fZJxhrK6XRq3759ioyM/N2zKKfql1bmy2dV2Eff4Q/7yT76Bn/YR8k/9vN09tEwDJWUlCgxMVFW64ln8nD7JGMNZbVaT3h3jCtERUX57A/OL9hH3+EP+8k++gZ/2EfJP/bzVPfxZGc8fsFTbQEAQKOifAAAgEblV+UjJCREjz32mE9PasY++g5/2E/20Tf4wz5K/rGfjbWPHjfgFAAA+Da/OvMBAADMR/kAAACNivIBAAAaFeUDAAA0KsoHAABoVH5TPl5//XWlpKQoNDRUPXv21Pfff292pFM2ceJE9e7dW5GRkYqLi9Mll1yiLVu21Fln7NixslgsdV79+vUzKfGpefzxx4/Zh/j4+Nr3DcPQ448/rsTERIWFhWnw4MHasGGDiYkbLjk5+Zh9tFgsGjdunCTvPI7fffedLrroIiUmJspisejzzz+v8359jpvD4dA999yj2NhYRURE6OKLL9aePXsacS9O7ET7WFVVpQkTJqhr166KiIhQYmKibrjhBu3bt6/O9xg8ePAxx3bUqFGNvCcndrJjWZ+fT28+lpKO+/tpsVj0wgsv1K7jyceyPp8XZvxO+kX5mDFjhsaPH68///nPWrVqlQYNGqRhw4YpJyfH7GinZNGiRRo3bpyWLl2qefPmqbq6WkOHDlVZWVmd9S644ALl5eXVvv7zn/+YlPjUdenSpc4+rFu3rva9559/Xi+++KJeffVVLV++XPHx8TrvvPNqH07oDZYvX15n/+bNmydJuvLKK2vX8bbjWFZWpoyMDL366qvHfb8+x238+PGaOXOmpk+frsWLF6u0tFQjRoxQTU1NY+3GCZ1oH8vLy5WVlaVHHnlEWVlZ+uyzz7R161ZdfPHFx6x766231jm2b775ZmPEr7eTHUvp5D+f3nwsJdXZt7y8PL377ruyWCy6/PLL66znqceyPp8XpvxOGn6gT58+xh133FFnWVpamvHQQw+ZlMi1CgoKDEnGokWLapeNGTPGGDlypHmhXOCxxx4zMjIyjvue0+k04uPjjWeffbZ2WUVFhWGz2Yw33nijkRK63n333We0a9fOcDqdhmF4/3GUZMycObP23/U5bkVFRUZQUJAxffr02nX27t1rWK1WY86cOY2Wvb5+u4/Hs2zZMkOSsXv37tplZ511lnHfffe5N5wLHW8/T/bz6YvHcuTIkcaQIUPqLPOmY/nbzwuzfid9/sxHZWWlVq5cqaFDh9ZZPnToUC1ZssSkVK5VXFwsSYqJiamzfOHChYqLi1OHDh106623qqCgwIx4p2Xbtm1KTExUSkqKRo0apZ07d0qSsrOzlZ+fX+e4hoSE6KyzzvLa41pZWampU6fqpptuqvNEZ184jr+oz3FbuXKlqqqq6qyTmJio9PR0rz22xcXFslgsio6OrrP8gw8+UGxsrLp06aIHH3zQq87a/eJEP5++diz379+v2bNn6+abbz7mPW85lr/9vDDrd9LjnmrraoWFhaqpqVGLFi3qLG/RooXy8/NNSuU6hmHo/vvv18CBA5Wenl67fNiwYbryyivVpk0bZWdn65FHHtGQIUO0cuVKr5kauG/fvnrvvffUoUMH7d+/X08//bQGDBigDRs21B674x3X3bt3mxH3tH3++ecqKirS2LFja5f5wnH8X/U5bvn5+QoODlbTpk2PWccbf2crKir00EMP6ZprrqnzlNBrr71WKSkpio+P1/r16/Xwww9rzZo1tZfevMHJfj597VhOmTJFkZGRuuyyy+os95ZjebzPC7N+J32+fPzif/9PUjp6EH67zBvdfffdWrt2rRYvXlxn+dVXX1373+np6erVq5fatGmj2bNnH/OL46mGDRtW+99du3ZV//791a5dO02ZMqV2UJsvHdd33nlHw4YNU2JiYu0yXziOx3Mqx80bj21VVZVGjRolp9Op119/vc57t956a+1/p6enKzU1Vb169VJWVpZ69OjR2FFPyan+fHrjsZSkd999V9dee61CQ0PrLPeWY/l7nxdS4/9O+vxll9jYWAUEBBzTzgoKCo5pet7mnnvu0ZdffqkFCxaoVatWJ1w3ISFBbdq00bZt2xopnetFRESoa9eu2rZtW+1dL75yXHfv3q358+frlltuOeF63n4c63Pc4uPjVVlZqcOHD//uOt6gqqpKV111lbKzszVv3rw6Zz2Op0ePHgoKCvLaYysd+/PpK8dSkr7//ntt2bLlpL+jkmcey9/7vDDrd9Lny0dwcLB69ux5zOmvefPmacCAASalOj2GYejuu+/WZ599pm+//VYpKSkn/ZqDBw8qNzdXCQkJjZDQPRwOhzZt2qSEhITaU5z/e1wrKyu1aNEirzyukydPVlxcnIYPH37C9bz9ONbnuPXs2VNBQUF11snLy9P69eu95tj+Ujy2bdum+fPnq1mzZif9mg0bNqiqqsprj6107M+nLxzLX7zzzjvq2bOnMjIyTrquJx3Lk31emPY7eUrDVL3M9OnTjaCgIOOdd94xNm7caIwfP96IiIgwdu3aZXa0U3LnnXcaNpvNWLhwoZGXl1f7Ki8vNwzDMEpKSowHHnjAWLJkiZGdnW0sWLDA6N+/v9GyZUvDbrebnL7+HnjgAWPhwoXGzp07jaVLlxojRowwIiMja4/bs88+a9hsNuOzzz4z1q1bZ4wePdpISEjwqn00DMOoqakxWrdubUyYMKHOcm89jiUlJcaqVauMVatWGZKMF1980Vi1alXtnR71OW533HGH0apVK2P+/PlGVlaWMWTIECMjI8Oorq42a7fqONE+VlVVGRdffLHRqlUrY/Xq1XV+Rx0Oh2EYhrF9+3bjiSeeMJYvX25kZ2cbs2fPNtLS0ozu3bt7zD4axon3s74/n958LH9RXFxshIeHG5MmTTrm6z39WJ7s88IwzPmd9IvyYRiG8dprrxlt2rQxgoODjR49etS5LdXbSDrua/LkyYZhGEZ5ebkxdOhQo3nz5kZQUJDRunVrY8yYMUZOTo65wRvo6quvNhISEoygoCAjMTHRuOyyy4wNGzbUvu90Oo3HHnvMiI+PN0JCQowzzzzTWLdunYmJT83cuXMNScaWLVvqLPfW47hgwYLj/nyOGTPGMIz6HbcjR44Yd999txETE2OEhYUZI0aM8Kj9PtE+Zmdn/+7v6IIFCwzDMIycnBzjzDPPNGJiYozg4GCjXbt2xr333mscPHjQ3B37jRPtZ31/Pr35WP7izTffNMLCwoyioqJjvt7Tj+XJPi8Mw5zfScvP4QAAABqFz4/5AAAAnoXyAQAAGhXlAwAANCrKBwAAaFSUDwAA0KgoHwAAoFFRPgAAQKOifAAAgEZF+QAAAI2K8gEAABoV5QMAADSq/wfERtEjt6yP8AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cumsum_vec = np.cumsum(np.insert(loss_history['total'], 0, 0)) \n",
    "print(cumsum_vec.shape)\n",
    "window_width = 10\n",
    "ma_vec = (cumsum_vec[window_width:] - cumsum_vec[:-window_width]) / window_width\n",
    "plt.plot(ma_vec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2255e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex_\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13770364623739334"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = embedding.detach().numpy()\n",
    "y = bc_dataset['labels']\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "y_hat = clf.predict(X)\n",
    "f1_score(y, y_hat, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e0df56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
